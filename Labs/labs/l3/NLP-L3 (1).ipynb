{"cells":[{"cell_type":"markdown","metadata":{"id":"y8SC3p-UCusw"},"source":["# L3: Attention"]},{"cell_type":"markdown","metadata":{"id":"nvKNkEYrCusy"},"source":["In this lab, you will implement the encoder‚Äìdecoder architecture presented in Lecture&nbsp;3.2 ([Sutskever et al., 2014](https://papers.nips.cc/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf)), including the attention-based extension presented in Lecture&nbsp;3.3 ([Bahdanau et al., 2015](https://arxiv.org/abs/1409.0473)), and evaluate this architecture on a machine translation task."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"IDNS-GhLCusz","executionInfo":{"status":"ok","timestamp":1676016275063,"user_tz":-60,"elapsed":3187,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["import torch"]},{"cell_type":"markdown","metadata":{"id":"BaYYbQq9Cus0"},"source":["Training the models in this notebook requires significant compute power, and we strongly recommend using a GPU."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"MJyOWDB6Cus1","executionInfo":{"status":"ok","timestamp":1676016275671,"user_tz":-60,"elapsed":610,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"aX-5kU7mCus1"},"source":["## The data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JmlJE9vBW96a","executionInfo":{"status":"ok","timestamp":1676016376942,"user_tz":-60,"elapsed":22923,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}},"outputId":"2a0877e8-f0e2-41d5-c5c6-ec89b73a6195"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"luSjyoOqCus2"},"source":["We will build a system that translates from German (our **source language**) to English (our **target language**). The dataset is a collection of parallel English‚ÄìGerman sentences taken from translations of subtitles for TED talks. It was derived from the [TED2013](https://opus.nlpl.eu/TED2013-v1.1.php) dataset, which is available in the [OPUS](http://opus.nlpl.eu/) collection. The code cell below prints the first lines in the training data:"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676016481712,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"EaFUyzF-Cus2","outputId":"71b5ff11-311c-4d98-e959-eb1fb9c79599"},"outputs":[{"output_type":"stream","name":"stdout","text":["0: david gallo : das ist bill lange . ich bin dave gallo . / david gallo : this is bill lange . i 'm dave gallo .\n","1: wir werden ihnen einige geschichten √ºber das meer in videoform erz√§hlen . / and we 're going to tell you some stories from the sea here in video .\n","2: ich denke , das problem ist , dass wir das meer f√ºr zu selbstverst√§ndlich halten . / and the problem , i think , is that we take the ocean for granted .\n","3: wenn man dar√ºber nachdenkt , machen die ozeane 75 % des planeten aus . / when you think about it , the oceans are 75 percent of the planet .\n","4: der gro√üteil der erde ist meerwasser . / most of the planet is ocean water .\n"]}],"source":["with open('/content/drive/MyDrive/TDDE09/labs/l3/train-de.txt', encoding=\"utf-8\") as src, open('/content/drive/MyDrive/TDDE09/labs/l3/train-en.txt', encoding=\"utf-8\") as tgt:\n","    for i, src_sentence, tgt_sentence in zip(range(5), src, tgt):\n","        print(f'{i}: {src_sentence.rstrip()} / {tgt_sentence.rstrip()}')"]},{"cell_type":"markdown","metadata":{"id":"cVYZFLVyCus3"},"source":["As you can see, some ‚Äòsentences‚Äô are actually *sequences* of sentences, but we will use the term *sentence* nevertheless. All sentences are whitespace-tokenised and lowercased. To make your life a bit easier, we have removed sentences longer than 25 words. \n","\n","The next cell contains code that yields the sentences contained in a file as lists of strings:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Eay_PCwACus4","executionInfo":{"status":"ok","timestamp":1676016479963,"user_tz":-60,"elapsed":583,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["def sentences(filename):\n","    with open(filename,encoding=\"utf-8\") as source:\n","        for line in source:\n","            yield line.rstrip().split()"]},{"cell_type":"markdown","metadata":{"id":"Ypi63gGlCus5"},"source":["## Problem 1: Build the vocabularies"]},{"cell_type":"markdown","metadata":{"id":"REbT89KqCus5"},"source":["Your first task is to build the vocabularies for the data, one vocabulary for each language. Each vocabulary should contain the 10,000 most frequent words in the training data for the respective language."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"R29hmyaRCus5","executionInfo":{"status":"ok","timestamp":1676016511685,"user_tz":-60,"elapsed":519,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["# https://www.geeksforgeeks.org/find-k-frequent-words-data-set-python/\n","# https://towardsdatascience.com/how-to-extract-key-from-python-dictionary-using-value-2b2f8dd2a995\n","import numpy as np\n","from collections import Counter\n","\n","def make_vocab(sentences, max_size):\n","    # TODO: Replace the next line with your own code\n","    sent_list = list(sentences)\n","    tokens = np.concatenate(sent_list)\n","    \n","    counter = Counter(tokens)\n","    thousand_most_freq = counter.most_common(max_size - 4)\n","    thousand_most_freq = {i[0]:idx+4 for idx, i in enumerate(thousand_most_freq)}\n","\n","    thousand_most_freq['<pad>'] = 0\n","    thousand_most_freq['<bos>'] = 1\n","    thousand_most_freq['<eos>'] = 2\n","    thousand_most_freq['<unk>'] = 3\n","    print(len(thousand_most_freq))\n","    return thousand_most_freq"]},{"cell_type":"markdown","metadata":{"id":"uQ8YnqoRCus6"},"source":["Your implementation must comply with the following specification:\n","\n","**make_vocab** (*sentences*, *max_size*)\n","\n","> Returns a dictionary that maps the most frequent words in the *sentences* to a contiguous range of integers starting at&nbsp;0. The first four mappings in this dictionary are reserved for the pseudowords `<pad>` (padding, id&nbsp;0), `<bos>` (beginning of sequence, id&nbsp;1), `<eos>` (end of sequence, id&nbsp;2), and `<unk>` (unknown word, id&nbsp;3). The parameter *max_size* caps the size of the dictionary, including the pseudowords."]},{"cell_type":"markdown","metadata":{"id":"Zmr7Oe9cCus7"},"source":["With this function, we can construct the vocabularies as follows:"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5952,"status":"ok","timestamp":1676016549337,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"onyml-oDCus7","outputId":"84345661-8a25-4e26-920d-f0de4d51d3aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n","10000\n"]}],"source":["src_vocab = make_vocab(sentences('/content/drive/MyDrive/TDDE09/labs/l3/train-de.txt'), 10000)\n","tgt_vocab = make_vocab(sentences('/content/drive/MyDrive/TDDE09/labs/l3/train-en.txt'), 10000)"]},{"cell_type":"markdown","metadata":{"id":"HX9T47dnCus8"},"source":["### ü§û Test your code\n","\n","To test you code, check that each vocabulary contains 10,000 words, including the pseudowords."]},{"cell_type":"markdown","metadata":{"id":"T2fQzgkPCus9"},"source":["## Load the data"]},{"cell_type":"markdown","metadata":{"id":"9MF4JRJVCus9"},"source":["The next cell defines a class for the parallel dataset. We sub-class the abstract [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class, which represents map-style datasets in PyTorch. This will let us use standard infrastructure related to the loading and automatic batching of data."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"TkFTb0LkCus9","executionInfo":{"status":"ok","timestamp":1676016553743,"user_tz":-60,"elapsed":454,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","class TranslationDataset(Dataset):\n","\n","    def __init__(self, src_vocab, src_filename, tgt_vocab, tgt_filename):\n","        self.src_vocab = src_vocab\n","        self.tgt_vocab = tgt_vocab\n","\n","        # We hard-wire the codes for <bos> (1), <eos> (2), and <unk> (3).\n","        self.src = [[self.src_vocab.get(w, 3) for w in s] for s in sentences(src_filename)]\n","        self.tgt = [[self.tgt_vocab.get(w, 3) for w in s] + [2] for s in sentences(tgt_filename)]\n","\n","    def __getitem__(self, idx):\n","        return self.src[idx], self.tgt[idx]\n","\n","    def __len__(self):\n","        return len(self.src)"]},{"cell_type":"markdown","metadata":{"id":"wnPlzxWrCus-"},"source":["We load the training data:"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"t1tyWbfbCus-","executionInfo":{"status":"ok","timestamp":1676016557894,"user_tz":-60,"elapsed":1813,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["train_dataset = TranslationDataset(src_vocab, '/content/drive/MyDrive/TDDE09/labs/l3/train-de.txt', tgt_vocab, '/content/drive/MyDrive/TDDE09/labs/l3/train-en.txt')"]},{"cell_type":"markdown","metadata":{"id":"BoUAW-GcCus_"},"source":["The following function will be helpful for debugging. It extracts a single source‚Äìtarget pair of sentences from the specified *dataset* and converts it into batches of size&nbsp;1, which can be fed into the encoder‚Äìdecoder model."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"DC2j_oZyCus_","executionInfo":{"status":"ok","timestamp":1676016557895,"user_tz":-60,"elapsed":4,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["def example(dataset, i):\n","    src, tgt = dataset[i]\n","    return torch.LongTensor(src).unsqueeze(0), torch.LongTensor(tgt).unsqueeze(0)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676016558346,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"dYhTBym7Cus_","outputId":"376b4706-1436-4f04-bc51-bc46a53886b6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1250,    3,   24,    8,   11, 1910,  377,    4,   10,  114, 9868,    3,\n","             4]]),\n"," tensor([[1246,    3,   46,   19,   15, 1342,    3,    4,   11,   78, 6960,    3,\n","             4,    2]]))"]},"metadata":{},"execution_count":32}],"source":["example(train_dataset, 0)"]},{"cell_type":"markdown","metadata":{"id":"Iw62gfhdCutA"},"source":["## Problem 2: The encoder‚Äìdecoder architecture"]},{"cell_type":"markdown","metadata":{"id":"nB280fFjCutA"},"source":["In this section, you will implement the encoder‚Äìdecoder architecture, including the extension of that architecture by an attention mechanism. The implementation consists of four parts: the encoder, the attention mechanism, the decoder, and a class that wraps the complete architecture."]},{"cell_type":"markdown","metadata":{"id":"XUFFRKwGCutA"},"source":["### Problem 2.1: Implement the encoder"]},{"cell_type":"markdown","metadata":{"id":"mKeHOZyxCutA"},"source":["The encoder is relatively straightforward. We look up word embeddings and unroll a bidirectional GRU over the embedding vectors to compute a representation at each token position. We then take the last hidden state of the forward GRU and the last hidden state of the backward GRU, concatenate them, and pass them through a linear layer. This produces a summary of the source sentence, which we will later feed into the decoder.\n","\n","To solve this problem, complete the skeleton code in the next code cell:"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1676016560010,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"klNT7vTPCutB"},"outputs":[],"source":["import torch.nn as nn\n","\n","class Encoder(nn.Module):\n","\n","    def __init__(self, num_words, embedding_dim=256, hidden_dim=512):\n","        super().__init__()\n","        self.embedding = nn.Embedding(num_words, embedding_dim, padding_idx=0)\n","        self.gru = nn.GRU(embedding_dim, hidden_dim, bidirectional = True, batch_first=True)\n","        self.linear = nn.Linear(hidden_dim*2, hidden_dim)\n","\n","    def forward(self, src):\n","        # TODO: Replace the next line with your own code\n","        embs = self.embedding(src)\n","        output, hidden = self.gru(embs)\n","        #print(hidden.size())\n","        hidden = torch.cat((hidden[-1], hidden[-2]), dim=1)\n","        #print(hidden.size())\n","        sum_of_src = self.linear(hidden)\n","        output = self.linear(output)\n","        #print(output.size())\n","        #print(sum_of_src.size())\n","\n","        return output, sum_of_src"]},{"cell_type":"markdown","metadata":{"id":"Ut1QP_1hCutB"},"source":["Your code must comply with the following specification:\n","\n","**__init__** (*num_words*, *embedding_dim* = 256, *hidden_dim* = 512)\n","\n","> Initialises the encoder. The encoder consists of an embedding layer that maps each of *num_words* words to an embedding vector of size *embedding_dim*, a bidirectional GRU that maps each embedding vector to a position-specific representation of size 2 √ó *hidden_dim*, and a final linear layer that projects these representationcons to new representations of size *hidden_dim*.\n","\n","**forward** (*self*, *src*)\n","\n","> Takes a tensor *src* with source-language word ids and sends it through the encoder. The input tensor has shape (*batch_size*, *src_len*), where *src_len* is the length of the sentences in the batch. (We will make sure that all sentences in the same batch have the same length.) The method returns a pair of tensors (*output*, *hidden*), where *output* has shape (*batch_size*, *src_len*, *hidden_dim*), and *hidden* has shape (*batch_size*, *hidden_dim*)."]},{"cell_type":"markdown","metadata":{"id":"xybpq39KCutC"},"source":["### ü§û Test your code\n","\n","To test your code, instantiate an encoder, feed it the first source sentence in the training data, and check that the tensors returned by the encoder have the expected shapes."]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676016561491,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"asldqJoNCd2Q","outputId":"0310c38d-69ad-4d89-d824-25dfd2c44e04"},"outputs":[{"output_type":"stream","name":"stdout","text":["output:  torch.Size([1, 13, 512])\n","hidden:  torch.Size([1, 512])\n"]}],"source":["src, tgt = example(train_dataset, 0)\n","encoder = Encoder(len(src_vocab))\n","output, hidden = encoder.forward(src)\n","\n","print(\"output: \", output.size())\n","print(\"hidden: \", hidden.size())"]},{"cell_type":"markdown","metadata":{"id":"LnD4At5uCutD"},"source":["### Problem 2.2: Implement the attention mechanism"]},{"cell_type":"markdown","metadata":{"id":"twmxl69tCutD"},"source":["Your next task is to implement the attention mechanism. Recall that the purpose of this mechanism is to inform the decoder when generating the translation of the next word. For this, attention has access to the previous hidden state of the decoder, as well as the complete output of the encoder. It returns the attention-weighted sum of the encoder output, the so-called *context* vector. For later usage, we also return the attention weights.\n","\n","As mentioned in Lecture&nbsp;3.3, attention can be implemented in various ways. One very simple implementation is *uniform attention*, which assigns equal weight to each position-specific representation in the output of the encoder, and completely ignores the hidden state of the decoder. This mechanism is implemented in the cell below."]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1676016563511,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"VK4LsCUfCutD"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","src_mask = (src != 0)\n","\n","class UniformAttention(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, decoder_hidden, encoder_output, src_mask):\n","        batch_size, src_len, _ = encoder_output.shape\n","\n","        # Set all attention scores to the same constant value (0). After\n","        # the softmax, we will have uniform weights.\n","        scores = torch.zeros(batch_size, src_len, device=encoder_output.device)\n","\n","        # Mask out the attention scores for the padding tokens. We set\n","        # them to -inf. After the softmax, we will have 0.\n","        scores.data.masked_fill_(~src_mask, -float('inf'))\n","\n","        # Convert scores into weights\n","        alpha = F.softmax(scores, dim=1)\n","\n","        # The context is the alpha-weighted sum of the encoder outputs.\n","        context = torch.bmm(alpha.unsqueeze(1), encoder_output).squeeze(1)\n","\n","        return context, alpha"]},{"cell_type":"markdown","metadata":{"id":"noYs0hSHCutE"},"source":["One technical detail in this code is our use of a mask *src_mask* to compute attention weights only for the ‚Äòreal‚Äô tokens in the source sentences, but not for the padding tokens that we introduce to bring all sentences in a batch to the same length.\n","\n","Your task now is to implement the attention mechanism from the paper by [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473). The relevant equation is in Section&nbsp;A.1.2:\n","\n","$$\n","a(s_{i-1}, h_j) = v^{\\top} \\tanh(W s_{i-1} + U h_j)\n","$$\n","\n","This equation specifies how to compute the attention score (a scalar) for the previous hidden state of the decoder, denoted by&nbsp;$s_{i-1}$, and the $j$th position-specific representation in the output of the encoder, denoted by&nbsp;$h_j$. The equation refers to three parameters: a vector $v$ and $W$ and $U$. In PyTorch, these parameters can be represented in terms of (bias-free) linear layers that are trained along with the other parameters of the model.\n","\n","Here is the skeleton code for this problem. As you can see, your specific task is to initialise the required parameters and to compute the attention scores (*scores*); the rest of the code is the same as for the uniform attention."]},{"cell_type":"markdown","metadata":{"id":"ZXSA6NMJFmSt"},"source":["#### s_i-1 == previous hidden state of the decoder\n","#### h_j   == position speicifc repr. in the output of the encoder\n","#### v     == linear\n","#### W     == linear\n","#### U     == linear"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":577,"status":"ok","timestamp":1676016567848,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"RyclW2osCutE"},"outputs":[],"source":["class BahdanauAttention(nn.Module):\n","\n","    def __init__(self, hidden_dim=512):\n","        super().__init__()\n","        # TODO: Add your code here\n","        self.W = nn.Linear(hidden_dim, hidden_dim, bias = False)\n","        self.U = nn.Linear(hidden_dim, hidden_dim, bias = False)\n","        self.v = nn.Linear(hidden_dim, 1, bias = False)\n","\n","    def forward(self, decoder_hidden, encoder_output, src_mask):\n","        batch_size, src_len, _ = encoder_output.shape\n","\n","        decoder_hidden = decoder_hidden.unsqueeze(1)\n","\n","        #print(\"decoder size: \", decoder_hidden.size())\n","        #print(\"encodier size: \", encoder_output.size())\n","        # TODO: Replace the next line with your own code\n","        W = self.W(decoder_hidden)\n","        U = self.U(encoder_output)\n","        \n","        tan_res = torch.tanh(W + U)\n","    \n","        scores = self.v(tan_res)\n","        scores = scores.squeeze(-1)#.squeeze(1).unsqueeze(0)\n","        #print(scores)\n","\n","        #scores = torch.zeros(batch_size, src_len, device=encoder_output.device)\n","\n","        # The rest of the code is as in UniformAttention\n","\n","        # Mask out the attention scores for the padding tokens. We set\n","        # them to -inf. After the softmax, we will have 0.\n","        scores.data.masked_fill_(~src_mask, -float('inf'))\n","\n","        # Convert scores into weights\n","        alpha = F.softmax(scores, dim=1)\n","\n","        # The context vector is the alpha-weighted sum of the encoder outputs.\n","        context = torch.bmm(alpha.unsqueeze(1), encoder_output).squeeze(1)\n","\n","        return context, alpha"]},{"cell_type":"markdown","metadata":{"id":"cTB0RPfDCutF"},"source":["Your code must comply with the following specification:\n","\n","**forward** (*decoder_hidden*, *encoder_output*, *src_mask*)\n","\n","> Takes the previous hidden state of the decoder (*decoder_hidden*) and the encoder output (*encoder_output*) and returns a pair (*context*, *alpha*) where *context* is the context as computed as in [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473), and *alpha* are the corresponding attention weights. The hidden state has shape (*batch_size*, *hidden_dim*), the encoder output has shape (*batch_size*, *src_len*, *hidden_dim*), the context has shape (*batch_size*, *hidden_dim*), and the attention weights have shape (*batch_size*, *src_len*)."]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1676016569373,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"qCOXKkVJE2Yl"},"outputs":[],"source":["import math\n","\n","class ScaledDotProductAttention(nn.Module):\n","\n","    def __init__(self, hidden_dim=512):\n","        super().__init__()\n","\n","    def forward(self, decoder_hidden, encoder_output, src_mask):\n","        # decoder_hidden: [batch_size, hidden_dim]\n","        # encoder_output: [batch_size, src_len, hidden_dim]\n","        # src_mask: [batch_size, src_len]\n","\n","        # Prepare the hidden state for broadcasting\n","        decoder_hidden = decoder_hidden.unsqueeze(1)\n","        # decoder_hidden: [batch_size, 1, hidden_dim]\n","\n","        # Compute the attention scores\n","        scores = decoder_hidden @ encoder_output.transpose(-1, -2)\n","        # scores: [batch_size, 1, src_len]\n","        scores = scores.squeeze(-2)\n","        # scores: [batch_size, src_len]\n","\n","        # Normalise\n","        scores /= math.sqrt(encoder_output.size(-1))\n","\n","        # Mask out the attention scores for the padding tokens. We set\n","        # them to -inf. After the softmax, we will have 0.\n","        scores.data.masked_fill_(~src_mask, -float('inf'))\n","\n","        # Convert scores into weights\n","        alpha = F.softmax(scores, dim=1)\n","        # alpha: [batch_size, src_len]\n","\n","        # The context vector is the alpha-weighted sum of the encoder outputs.\n","        context = torch.bmm(alpha.unsqueeze(1), encoder_output).squeeze(1)\n","        # context: [batch_size, encoder_hidden_dim]\n","\n","        return context, alpha"]},{"cell_type":"markdown","metadata":{"id":"OxNwwlmuCutF"},"source":["### ü§û Test your code\n","\n","To test your code, extend your test from Problem&nbsp;2.1: Feed the output of your encoder into your attention class. As the previous hidden state of the decoder, you can use the hidden state returned by the encoder. You will also need to create a source mask; this can be done as follows:\n","\n","```\n","src_mask = (src != 0)\n","```\n","\n","Check that the context tensor and the attention weights returned by the attention class have the expected shapes."]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1676016576561,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"EE2bFb7ZNvv8","outputId":"7aa6b2bb-0fdf-460e-af90-f20b21d1cfcb"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 512])\n","torch.Size([1, 13])\n"]}],"source":["src, tgt = example(train_dataset, 0)\n","encoder = Encoder(len(src_vocab))\n","output, hidden = encoder.forward(src)\n","\n","bad_att = BahdanauAttention()\n","context, alpha = bad_att.forward(hidden, output, src_mask)\n","print(context.size())\n","print(alpha.size())"]},{"cell_type":"markdown","metadata":{"id":"fB2A4Qa1CutG"},"source":["### Problem 2.3: Implement the decoder"]},{"cell_type":"markdown","metadata":{"id":"AO_4A4XXCutH"},"source":["Now you are ready to implement the decoder. Like the encoder, the decoder is based on a GRU; but this time we use a unidirectional network, as we generate the target sentences left-to-right.\n","\n","**‚ö†Ô∏è We expect that solving this problem will take you the longest time in this lab.**\n","\n","Because the decoder is an autoregressive model, we need to unroll the GRU ‚Äòmanually‚Äô: At each position, we take the previous hidden state as well as the new input, and apply the GRU for one step. The initial hidden state comes from the encoder. The new input is the embedding of the previous word, concatenated with the context vector from the attention model. To produce the final output, we take the output of the GRU, concatenate the embedding vector and the context vector (residual connection), and feed the result into a linear layer. Here is a graphical representation:\n","\n","<img src=\"https://gitlab.liu.se/nlp/nlp-course/-/raw/master/labs/l5/decoder.svg\" width=\"50%\" alt=\"Decoder architecture\"/>\n","\n","We need to implement this manual unrolling for two very similar tasks: When *training*, both the inputs to and the target outputs of the GRU come from the training data. When *decoding*, the outputs of the GRU are used to generate new target-side words, and these words become the inputs to the next step of the unrolling. We have implemented methods `forward` and `decode` for these two different modes of usage. Your task is to implement a method `step` that takes a single step with the GRU."]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":457,"status":"ok","timestamp":1676016579160,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"xBDjsJ-1CutH"},"outputs":[],"source":["class Decoder(nn.Module):\n","\n","    def __init__(self, num_words, attention, embedding_dim=256, hidden_dim=512):\n","        super().__init__()\n","        self.embedding = nn.Embedding(num_words, embedding_dim)\n","        self.attention = attention\n","        self.gru       = nn.GRU(embedding_dim + hidden_dim, hidden_dim, batch_first = True)\n","        self.linear    = nn.Linear(embedding_dim + hidden_dim*2, num_words)\n","        # TODO: Add your own code\n","\n","    def forward(self, encoder_output, hidden, src_mask, tgt):\n","        batch_size, tgt_len = tgt.shape\n","\n","        # Lookup the embeddings for the previous words\n","        embedded = self.embedding(tgt)\n","\n","        # Initialise the list of outputs (in each sentence)\n","        outputs = []\n","\n","        for i in range(tgt_len):\n","            # Get the embedding for the previous word (in each sentence)\n","            prev_embedded = embedded[:, i]\n","\n","            # Take one step with the RNN\n","            output, hidden, alpha = self.step(encoder_output, hidden, src_mask, prev_embedded)\n","\n","            # Update the list of outputs (in each sentence)\n","            outputs.append(output.unsqueeze(1))\n","\n","        return torch.cat(outputs, dim=1)\n","\n","    def decode(self, encoder_output, hidden, src_mask, max_len):\n","        batch_size = encoder_output.size(0)\n","\n","        # Initialise the list of generated words and attention weights (in each sentence)\n","        generated = [torch.ones(batch_size, dtype=torch.long, device=hidden.device)]\n","        alphas = []\n","\n","        for i in range(max_len):\n","            # Get the embedding for the previous word (in each sentence)\n","            prev_embedded = self.embedding(generated[-1])\n","\n","            # Take one step with the RNN\n","            output, hidden, alpha = self.step(encoder_output, hidden, src_mask, prev_embedded)\n","\n","            # Update the list of generated words and attention weights (in each sentence)\n","            generated.append(output.argmax(-1))\n","            alphas.append(alpha)\n","\n","        generated = [x.unsqueeze(1) for x in generated[1:]]\n","        alphas = [x.unsqueeze(1) for x in alphas]\n","            \n","        return torch.cat(generated, dim=1), torch.cat(alphas, dim=1)\n","\n","    def step(self, encoder_output, hidden, src_mask, prev_embedded):\n","        # TODO: Replace the next line with your own code\n","        context, alpha = self.attention.forward(hidden, encoder_output, src_mask)\n","        cat = torch.cat((context, prev_embedded), dim = 1).unsqueeze(1)\n","\n","        output, hidden_layer = self.gru(cat, hidden.unsqueeze(0))\n","        second_concatination = torch.cat((output.squeeze(1), cat.squeeze(1)), dim=1)\n","\n","        output = self.linear(second_concatination)\n","        \n","        #print(\"output: \", output.size())\n","        #print(\"hidden: \", hidden_layer.size())\n","        #print(\"alpha: \", alpha.size())\n","\n","        return output, hidden_layer.squeeze(0), alpha"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1676016597547,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"YGA6byrEnAN-","outputId":"1b887242-ed9c-46c3-be61-8ece5dbf932a"},"outputs":[{"output_type":"stream","name":"stdout","text":["something:  torch.Size([1, 14, 10000])\n"]}],"source":["src, tgt = example(train_dataset, 0)\n","encoder = Encoder(len(src_vocab))\n","output, hidden = encoder.forward(src)\n","\n","attn = BahdanauAttention()\n","decoder = Decoder(len(tgt_vocab), attn)\n","#contexts, alphas = decoder.decode(output, hidden, src_mask, 10000)\n","something = decoder.forward(output, hidden, src_mask, tgt)\n","print(\"something: \", something.size())"]},{"cell_type":"markdown","metadata":{"id":"ej2-lzyVCutH"},"source":["Your implementation should comply with the following specification:\n","\n","**step** (*self*, *encoder_output*, *hidden*, *src_mask*, *prev_embedded*)\n","\n","> Performs a single step in the manual unrolling of the decoder GRU. This takes the output of the encoder (*encoder_output*), the previous hidden state of the decoder (*hidden*), the source mask as described in Problem&nbsp;2.2 (*src_mask*), and the embedding vector of the previous word (*prev_embedded*), and computes the output as described above.\n",">\n","> The shape of *encoder_output* is (*batch_size*, *src_len*, *hidden_dim*); the shape of *hidden* is (*batch_size*, *hidden_dim*); the shape of *src_mask* is (*batch_size*, *src_len*); and the shape of *prev_embedded* is (*batch_size*, *embedding_dim*).\n",">\n","> The method returns a triple of tensors (*output*, *hidden*, *alpha*) where *output* is the position-specific output of the GRU, of shape (*batch_size*, *num_words*); *hidden* is the new hidden state, of shape (*batch_size*, *hidden_dim*); and *alpha* are the attention weights that were used to compute the *output*, of shape (*batch_size*, *src_len*).\n","\n","#### üí° Hints on the implementation\n","\n","**Batch first!** Per default, the GRU implementation in PyTorch (just as the LSTM implementation) expects its input to be a three-dimensional tensor of the form (*seq_len*, *batch_size*, *input_size*). We find it conceptually easier to change this default behaviour and let the models take their input in the form (*batch_size*, *seq_len*, *input_size*). To do so, set *batch_first=True* when instantiating the GRU.\n","\n","**Unsqueeze and squeeze.** When doing the unrolling manually, we get the input in the form (*batch_size*, *input_size*). To convert between this representation and the (*batch_size*, *seq_len*, *input_size*) representation, you can use [`unsqueeze`](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html) and [`squeeze`](https://pytorch.org/docs/stable/generated/torch.squeeze.html)."]},{"cell_type":"markdown","metadata":{"id":"cFvNiX-YCutI"},"source":["### ü§û Test your code\n","\n","To test your code, extend your test from the previous problems, and simulate a complete forward pass of the encoder‚Äìdecoder architecture on the example sentence. Check the shapes of the resulting tensors."]},{"cell_type":"markdown","metadata":{"id":"70yHTFS9CutJ"},"source":["### Encoder‚Äìdecoder wrapper class"]},{"cell_type":"markdown","metadata":{"id":"DeKfvES5CutJ"},"source":["The last part of the implementation is a class that wraps the encoder and the decoder as a single model:"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1676016598823,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"lUjIGniZCutJ"},"outputs":[],"source":["class EncoderDecoder(nn.Module):\n","\n","    def __init__(self, src_vocab_size, tgt_vocab_size, attention):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size)\n","        self.decoder = Decoder(tgt_vocab_size, attention)\n","\n","    def forward(self, src, tgt):\n","        encoder_output, hidden = self.encoder(src)\n","        return self.decoder.forward(encoder_output, hidden, src != 0, tgt)\n","\n","    def decode(self, src, max_len):\n","        encoder_output, hidden = self.encoder(src)\n","        return self.decoder.decode(encoder_output, hidden, src != 0, max_len)"]},{"cell_type":"markdown","metadata":{"id":"u3uW3TKACutK"},"source":["### ü§û Test your code\n","\n","As a final test, instantiate an encoder‚Äìdecoder model and use it to decode the example sentence. Check the shapes of the resulting tensors."]},{"cell_type":"markdown","metadata":{"id":"laK9bbq8CutL"},"source":["## Problem 3: Train a translator"]},{"cell_type":"markdown","metadata":{"id":"Q68aWc_2CutL"},"source":["We now have all the pieces to build and train a complete translation system."]},{"cell_type":"markdown","metadata":{"id":"w5MYw2PJCutL"},"source":["### Translator class\n","\n","We first define a class `Translator` that initialises an encoder‚Äìdecoder model and uses it to translate sentences. It can also return the attention weights that were used to produce the translation of each sentence."]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":625,"status":"ok","timestamp":1676016602669,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"Evi-J7BfCutM"},"outputs":[],"source":["class Translator(object):\n","\n","    def __init__(self, src_vocab, tgt_vocab, attention, device=torch.device('cpu')):\n","        self.src_vocab = src_vocab\n","        self.tgt_vocab = tgt_vocab\n","        self.device = device\n","        self.model = EncoderDecoder(len(src_vocab), len(tgt_vocab), attention).to(device)\n","\n","    def translate_with_attention(self, sentences):\n","        # Encode each sentence\n","        encoded = [[self.src_vocab.get(w, 3) for w in s.split()] for s in sentences]\n","\n","        # Determine the maximal length of an encoded sentence\n","        max_len = max(len(e) for e in encoded)\n","\n","        # Build the input tensor, padding all sequences to the same length\n","        src = torch.LongTensor([e + [0] * (max_len - len(e)) for e in encoded]).to(self.device)\n","\n","        # Run the decoder and convert the result into nested lists\n","        with torch.no_grad():\n","            decoded, alphas = tuple(d.cpu().numpy().tolist() for d in self.model.decode(src, 2 * max_len))\n","\n","        # Prune each decoded sentence after the first <eos>\n","        i2w = {i: w for w, i in self.tgt_vocab.items()}\n","        result = []\n","        for d, a in zip(decoded, alphas):\n","            d = [i2w[i] for i in d]\n","            try:\n","                eos_index = d.index('<eos>')\n","                del d[eos_index:]\n","                del a[eos_index:]\n","            except:\n","                pass\n","            result.append((' '.join(d), a))\n","\n","        return result\n","\n","    def translate(self, sentences):\n","        translated, alphas = zip(*self.translate_with_attention(sentences))\n","        return translated"]},{"cell_type":"markdown","metadata":{"id":"2660iyt-CutN"},"source":["The code below shows how this class is supposed to be used:"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1676016604894,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"NFiJLKRXCutN","outputId":"9ebd8657-455c-44c0-e4d1-ced2aa1c20db"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('estimates middle brave storytelling nobel heated 16 imaginative 20th sunlight',\n"," 'estimates middle brave storytelling nobel heated sane channel programmers succeeded')"]},"metadata":{},"execution_count":43}],"source":["translator = Translator(src_vocab, tgt_vocab, BahdanauAttention())\n","translator.translate(['ich wei√ü nicht .', 'das haus ist klein .'])"]},{"cell_type":"markdown","metadata":{"id":"2cFT9atlCutO"},"source":["### Evaluation function\n","\n","As mentioned in Lecture&nbsp;3.1, machine translation systems are typically evaluated using the BLEU metric. Here we use the implementation of this metric from the `sacrebleu` library."]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":6545,"status":"ok","timestamp":1676016621498,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"LrN8uYX5CutO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e6982d1-ae8f-454c-8850-ab50e3ebcc55"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.2)\n","Installing collected packages: portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.6 portalocker-2.7.0 sacrebleu-2.3.1\n"]}],"source":["# If sacrebleu is not found, uncomment the next line:\n","!pip install sacrebleu\n","\n","import sacrebleu\n","\n","def bleu(translator, src, ref):\n","    translated = translator.translate(src)\n","    return sacrebleu.raw_corpus_bleu(translated, [ref], 0.01).score"]},{"cell_type":"markdown","metadata":{"id":"Ozk1hurqCutP"},"source":["We will report the BLEU score on the validation data:"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":2203,"status":"ok","timestamp":1676016651224,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"HNtBMDVqCutP"},"outputs":[],"source":["with open('/content/drive/MyDrive/TDDE09/labs/l3/valid-de.txt') as src, open('/content/drive/MyDrive/TDDE09/labs/l3/valid-en.txt') as ref:\n","    valid_src = [line.rstrip() for line in src]\n","    valid_ref = [line.rstrip() for line in ref]"]},{"cell_type":"markdown","metadata":{"id":"xe2rPzwmCutQ"},"source":["### Batcher class\n","\n","To prepare the training, we next create a class that takes a batch of encoded parallel sentences (a pair of lists of integers) and transforms it into two tensors, one for the source side and one for the target side. Each tensor contains sequences padded to the length of the longest sequence."]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":435,"status":"ok","timestamp":1676016738574,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"X-yfmnSzCutQ"},"outputs":[],"source":["class TranslationBatcher(object):\n","\n","    def __init__(self, device):\n","        self.device = device\n","\n","    def __call__(self, batch):\n","        srcs, tgts = zip(*batch)\n","\n","        # Determine the maximal length of a source/target sequence\n","        max_src_len = max(len(s) for s in srcs)\n","        max_tgt_len = max(len(t) for t in tgts)\n","\n","        # Create the source/target tensors\n","        S = torch.LongTensor([s + [0] * (max_src_len - len(s)) for s in srcs])\n","        T = torch.LongTensor([t + [0] * (max_tgt_len - len(t)) for t in tgts])\n","\n","        return S.to(self.device), T.to(self.device)"]},{"cell_type":"markdown","metadata":{"id":"FfM1Ov-sCutQ"},"source":["### Training loop\n","\n","The training loop resembles the training loops that you have seen in previous labs, except that we use a few new utilities from the PyTorch ecosystem."]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":553,"status":"ok","timestamp":1676016859068,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"yr4VP-SpCutQ"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","def train(n_epochs=2, batch_size=128, lr=5e-4):\n","    # Build the vocabularies\n","    vocab_src = make_vocab(sentences('/content/drive/MyDrive/TDDE09/labs/l3/train-de.txt'), 10000)\n","    vocab_tgt = make_vocab(sentences('/content/drive/MyDrive/TDDE09/labs/l3/train-en.txt'), 10000)\n","\n","    # Prepare the dataset\n","    train_dataset = TranslationDataset(vocab_src, '/content/drive/MyDrive/TDDE09/labs/l3/train-de.txt', vocab_tgt, '/content/drive/MyDrive/TDDE09/labs/l3/train-en.txt')\n","\n","    # Prepare the data loaders\n","    batcher = TranslationBatcher(device)\n","    train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=batcher)\n","\n","    # Build the translator\n","    translator = Translator(src_vocab, tgt_vocab, ScaledDotProductAttention(), device=device)\n","\n","    # Initialise the optimiser\n","    optimizer = torch.optim.Adam(translator.model.parameters(), lr=lr)\n","\n","    # Make it possible to interrupt the training\n","    try:\n","        for epoch in range(n_epochs):\n","            losses = []\n","            bleu_valid = 0\n","            sample = '<none>'\n","            with tqdm(total=len(train_dataset)) as pbar:\n","                for i, (src_batch, tgt_batch) in enumerate(train_loader):\n","                    # Create a shifted version of tgt_batch containing the previous words\n","                    batch_size, tgt_len = tgt_batch.shape\n","                    bos = torch.ones(batch_size, 1, dtype=torch.long, device=tgt_batch.device)\n","                    tgt_batch_shifted = torch.cat((bos, tgt_batch[:, :-1]), dim=1)\n","\n","                    translator.model.train()\n","\n","                    # Forward pass\n","                    scores = translator.model(src_batch, tgt_batch_shifted)\n","                    scores = scores.view(-1, len(tgt_vocab))\n","\n","                    # Backward pass\n","                    optimizer.zero_grad()\n","                    loss = F.cross_entropy(scores, tgt_batch.view(-1), ignore_index=0)\n","                    loss.backward()\n","                    optimizer.step()\n","\n","                    # Update the diagnostics\n","                    losses.append(loss.item())\n","                    pbar.set_postfix(loss=(sum(losses) / len(losses)), bleu_valid=bleu_valid, sample=sample)\n","                    pbar.update(len(src_batch))\n","\n","                    if i % 50 == 0:\n","                        translator.model.eval()\n","                        bleu_valid = int(bleu(translator, valid_src, valid_ref))\n","                        sample = translator.translate(['das haus ist klein .'])[0]\n","\n","    except KeyboardInterrupt:\n","        pass\n","\n","    return translator"]},{"cell_type":"markdown","metadata":{"id":"KgXElolrCutR"},"source":["Now it is time to train the system. During training, two diagnostics will be printed periodically: the running average of the training loss, the BLEU score on the validation data, and the translation of a sample sentence, *das haus ist klein* (which should translate into *the house is small*).\n","\n","As mentioned before, training the translator takes quite a bit of compute power and time. Even with a GPU, you should expect training times per epoch of about 8‚Äì10 minutes. The default number of epochs is&nbsp;2; however, you may want to interrupt the training prematurely and use a partially trained model in case you run out of time."]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376728,"status":"ok","timestamp":1676017239083,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"},"user_tz":-60},"id":"VW8wF8oRCutR","outputId":"aeeb9902-bb89-405e-9638-b9967fe64fa4"},"outputs":[{"output_type":"stream","name":"stdout","text":["10000\n","10000\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 143121/143121 [03:00<00:00, 791.65it/s, bleu_valid=14, loss=3.76, sample=it 's a little bit .]\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 143121/143121 [03:08<00:00, 758.45it/s, bleu_valid=19, loss=2.64, sample=this is small .]\n"]}],"source":["translator = train()"]},{"cell_type":"markdown","metadata":{"id":"3Oq5Lz7mCutR"},"source":["**‚ö†Ô∏è Your submitted notebook must contain output demonstrating at least 16 BLEU points on the validation data.**"]},{"cell_type":"markdown","metadata":{"id":"7677Q0QLCutS"},"source":["## Problem 4: Visualising attention (reflection)\n"]},{"cell_type":"markdown","metadata":{"id":"OCzHCB4XCutS"},"source":["Figure&nbsp;3 in the paper by [Bahdanau et al. (2015)](https://arxiv.org/abs/1409.0473) shows some heatmaps of attention weights in selected sentences. In the last problem of this lab, we ask you to inspect attention weights for your trained translation system. We define a function `plot_attention` that visualises the attention weights. The *x* axis corresponds to the words in the source sentence (German) and the *y* axis to the generated target sentence (English). The heatmap colours represent the strengths of the attention weights."]},{"cell_type":"code","execution_count":52,"metadata":{"id":"IXHPiuamCutS","executionInfo":{"status":"ok","timestamp":1676017239083,"user_tz":-60,"elapsed":11,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","%config InlineBackend.figure_format = 'svg'\n","\n","plt.style.use('seaborn')\n","\n","def plot_attention(translator, sentence):\n","    translation, weights = translator.translate_with_attention([sentence])[0]\n","    weights = np.array(weights)\n","\n","    fig, ax = plt.subplots()\n","    heatmap = ax.pcolor(weights, cmap='Blues_r')\n","\n","    ax.set_xticklabels(sentence.split(), minor=False, rotation='vertical')\n","    ax.set_yticklabels(translation.split(), minor=False)\n","\n","    ax.xaxis.tick_top()\n","    ax.set_xticks(np.arange(weights.shape[1]) + 0.5, minor=False)\n","    ax.set_yticks(np.arange(weights.shape[0]) + 0.5, minor=False)\n","    ax.invert_yaxis()\n","\n","    plt.colorbar(heatmap)"]},{"cell_type":"markdown","metadata":{"id":"SGCwchIdCutS"},"source":["Here is an example:"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"Hj4teeITCutT","colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"status":"ok","timestamp":1676017240026,"user_tz":-60,"elapsed":946,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}},"outputId":"eb4a0d8b-34f8-432b-c02e-a0c4ea80b58d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x396 with 2 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"349.83625pt\" version=\"1.1\" viewBox=\"0 0 463.93275 349.83625\" width=\"463.93275pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 349.83625 \nL 463.93275 349.83625 \nL 463.93275 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 41.44375 342.63625 \nL 398.56375 342.63625 \nL 398.56375 43.65625 \nL 41.44375 43.65625 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\"/>\n     <g id=\"text_1\">\n      <!-- es -->\n      <defs>\n       <path d=\"M 13.484375 24.5625 \nQ 13.484375 20.40625 14.328125 16.90625 \nQ 15.1875 13.421875 16.96875 10.90625 \nQ 18.75 8.40625 21.53125 7 \nQ 24.3125 5.609375 28.21875 5.609375 \nQ 33.9375 5.609375 37.375 7.90625 \nQ 40.828125 10.203125 42.046875 13.71875 \nL 49.75 11.53125 \nQ 48.921875 9.328125 47.4375 7.109375 \nQ 45.953125 4.890625 43.453125 3.09375 \nQ 40.96875 1.3125 37.234375 0.15625 \nQ 33.5 -0.984375 28.21875 -0.984375 \nQ 16.5 -0.984375 10.375 6 \nQ 4.25 12.984375 4.25 26.765625 \nQ 4.25 34.1875 6.09375 39.328125 \nQ 7.953125 44.484375 11.171875 47.703125 \nQ 14.40625 50.921875 18.703125 52.359375 \nQ 23 53.8125 27.875 53.8125 \nQ 34.515625 53.8125 38.984375 51.65625 \nQ 43.453125 49.515625 46.15625 45.71875 \nQ 48.875 41.9375 50.015625 36.8125 \nQ 51.171875 31.6875 51.171875 25.734375 \nL 51.171875 24.5625 \nz\nM 42.09375 31.296875 \nQ 41.359375 39.65625 37.84375 43.484375 \nQ 34.328125 47.3125 27.734375 47.3125 \nQ 25.53125 47.3125 23.109375 46.609375 \nQ 20.703125 45.90625 18.65625 44.09375 \nQ 16.609375 42.28125 15.1875 39.171875 \nQ 13.765625 36.078125 13.578125 31.296875 \nz\n\" id=\"LiberationSans-101\"/>\n       <path d=\"M 46.390625 14.59375 \nQ 46.390625 10.890625 44.9375 7.984375 \nQ 43.5 5.078125 40.765625 3.09375 \nQ 38.03125 1.125 34.046875 0.0625 \nQ 30.078125 -0.984375 24.953125 -0.984375 \nQ 20.359375 -0.984375 16.671875 -0.265625 \nQ 12.984375 0.4375 10.203125 2 \nQ 7.421875 3.5625 5.53125 6.125 \nQ 3.65625 8.6875 2.78125 12.40625 \nL 10.546875 13.921875 \nQ 11.671875 9.671875 15.1875 7.6875 \nQ 18.703125 5.71875 24.953125 5.71875 \nQ 27.78125 5.71875 30.140625 6.109375 \nQ 32.515625 6.5 34.21875 7.453125 \nQ 35.9375 8.40625 36.890625 9.984375 \nQ 37.84375 11.578125 37.84375 13.921875 \nQ 37.84375 16.3125 36.71875 17.84375 \nQ 35.59375 19.390625 33.59375 20.40625 \nQ 31.59375 21.4375 28.734375 22.1875 \nQ 25.875 22.953125 22.46875 23.875 \nQ 19.28125 24.703125 16.15625 25.734375 \nQ 13.03125 26.765625 10.515625 28.4375 \nQ 8.015625 30.125 6.453125 32.609375 \nQ 4.890625 35.109375 4.890625 38.875 \nQ 4.890625 46.09375 10.03125 49.875 \nQ 15.1875 53.65625 25.046875 53.65625 \nQ 33.796875 53.65625 38.9375 50.578125 \nQ 44.09375 47.515625 45.453125 40.71875 \nL 37.546875 39.75 \nQ 37.109375 41.796875 35.9375 43.1875 \nQ 34.765625 44.578125 33.109375 45.4375 \nQ 31.453125 46.296875 29.375 46.65625 \nQ 27.296875 47.015625 25.046875 47.015625 \nQ 19.09375 47.015625 16.25 45.203125 \nQ 13.421875 43.40625 13.421875 39.75 \nQ 13.421875 37.59375 14.46875 36.203125 \nQ 15.53125 34.8125 17.40625 33.859375 \nQ 19.28125 32.90625 21.921875 32.203125 \nQ 24.5625 31.5 27.734375 30.71875 \nQ 29.828125 30.171875 32.03125 29.5625 \nQ 34.234375 28.953125 36.296875 28.09375 \nQ 38.375 27.25 40.203125 26.09375 \nQ 42.046875 24.953125 43.40625 23.34375 \nQ 44.78125 21.734375 45.578125 19.578125 \nQ 46.390625 17.4375 46.390625 14.59375 \nz\n\" id=\"LiberationSans-115\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(73.789688 36.65625)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-101\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-115\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\"/>\n     <g id=\"text_2\">\n      <!-- war -->\n      <defs>\n       <path d=\"M 57.328125 0 \nL 47.125 0 \nL 38.671875 34.078125 \nQ 38.28125 35.40625 37.859375 37.359375 \nQ 37.453125 39.3125 37.0625 41.15625 \nQ 36.578125 43.3125 36.140625 45.609375 \nQ 35.6875 43.40625 35.203125 41.265625 \nQ 34.8125 39.40625 34.34375 37.40625 \nQ 33.890625 35.40625 33.5 33.890625 \nL 24.8125 0 \nL 14.65625 0 \nL -0.140625 52.828125 \nL 8.546875 52.828125 \nL 17.484375 16.9375 \nQ 17.828125 15.828125 18.15625 14.1875 \nQ 18.5 12.546875 18.84375 10.984375 \nQ 19.1875 9.1875 19.578125 7.28125 \nQ 19.96875 9.125 20.40625 10.890625 \nQ 20.796875 12.40625 21.1875 13.96875 \nQ 21.578125 15.53125 21.875 16.546875 \nL 31.453125 52.828125 \nL 40.875 52.828125 \nL 50.09375 16.546875 \nQ 50.4375 15.28125 50.828125 13.671875 \nQ 51.21875 12.0625 51.5625 10.640625 \nQ 51.953125 8.984375 52.34375 7.28125 \nQ 52.734375 9.125 53.125 10.890625 \nQ 53.46875 12.40625 53.828125 14.03125 \nQ 54.203125 15.671875 54.546875 16.9375 \nL 63.875 52.828125 \nL 72.46875 52.828125 \nz\n\" id=\"LiberationSans-119\"/>\n       <path d=\"M 20.21875 -0.984375 \nQ 12.25 -0.984375 8.25 3.21875 \nQ 4.25 7.421875 4.25 14.75 \nQ 4.25 19.96875 6.21875 23.3125 \nQ 8.203125 26.65625 11.390625 28.5625 \nQ 14.59375 30.46875 18.6875 31.203125 \nQ 22.796875 31.9375 27.046875 32.03125 \nL 38.921875 32.234375 \nL 38.921875 35.109375 \nQ 38.921875 38.375 38.234375 40.671875 \nQ 37.546875 42.96875 36.125 44.375 \nQ 34.71875 45.796875 32.59375 46.453125 \nQ 30.46875 47.125 27.59375 47.125 \nQ 25.046875 47.125 23 46.75 \nQ 20.953125 46.390625 19.4375 45.4375 \nQ 17.921875 44.484375 16.984375 42.84375 \nQ 16.0625 41.21875 15.765625 38.71875 \nL 6.59375 39.546875 \nQ 7.078125 42.671875 8.4375 45.28125 \nQ 9.8125 47.90625 12.328125 49.796875 \nQ 14.84375 51.703125 18.625 52.75 \nQ 22.40625 53.8125 27.78125 53.8125 \nQ 37.75 53.8125 42.765625 49.234375 \nQ 47.796875 44.671875 47.796875 36.03125 \nL 47.796875 13.28125 \nQ 47.796875 9.375 48.828125 7.390625 \nQ 49.859375 5.421875 52.734375 5.421875 \nQ 53.46875 5.421875 54.203125 5.515625 \nQ 54.9375 5.609375 55.609375 5.765625 \nL 55.609375 0.296875 \nQ 53.953125 -0.09375 52.3125 -0.28125 \nQ 50.6875 -0.484375 48.828125 -0.484375 \nQ 46.34375 -0.484375 44.5625 0.171875 \nQ 42.78125 0.828125 41.65625 2.171875 \nQ 40.53125 3.515625 39.9375 5.484375 \nQ 39.359375 7.46875 39.203125 10.109375 \nL 38.921875 10.109375 \nQ 37.5 7.5625 35.8125 5.515625 \nQ 34.125 3.46875 31.875 2.03125 \nQ 29.640625 0.59375 26.78125 -0.1875 \nQ 23.921875 -0.984375 20.21875 -0.984375 \nz\nM 22.21875 5.609375 \nQ 26.421875 5.609375 29.5625 7.140625 \nQ 32.71875 8.6875 34.78125 11.078125 \nQ 36.859375 13.484375 37.890625 16.3125 \nQ 38.921875 19.140625 38.921875 21.734375 \nL 38.921875 26.078125 \nL 29.296875 25.875 \nQ 26.078125 25.828125 23.171875 25.40625 \nQ 20.265625 25 18.0625 23.78125 \nQ 15.875 22.5625 14.578125 20.359375 \nQ 13.28125 18.171875 13.28125 14.59375 \nQ 13.28125 10.296875 15.59375 7.953125 \nQ 17.921875 5.609375 22.21875 5.609375 \nz\n\" id=\"LiberationSans-97\"/>\n       <path d=\"M 6.9375 0 \nL 6.9375 40.53125 \nQ 6.9375 42.1875 6.90625 43.921875 \nQ 6.890625 45.65625 6.828125 47.265625 \nQ 6.78125 48.875 6.734375 50.28125 \nQ 6.6875 51.703125 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 51.703125 15.0625 50.265625 \nQ 15.140625 48.828125 15.203125 47.3125 \nQ 15.28125 45.796875 15.296875 44.40625 \nQ 15.328125 43.015625 15.328125 42.046875 \nL 15.53125 42.046875 \nQ 16.453125 45.0625 17.5 47.28125 \nQ 18.5625 49.515625 19.96875 50.953125 \nQ 21.390625 52.390625 23.34375 53.09375 \nQ 25.296875 53.8125 28.078125 53.8125 \nQ 29.15625 53.8125 30.125 53.640625 \nQ 31.109375 53.46875 31.640625 53.328125 \nL 31.640625 45.265625 \nQ 30.765625 45.515625 29.59375 45.625 \nQ 28.421875 45.75 26.953125 45.75 \nQ 23.921875 45.75 21.796875 44.375 \nQ 19.671875 43.015625 18.328125 40.59375 \nQ 17 38.1875 16.359375 34.84375 \nQ 15.71875 31.5 15.71875 27.546875 \nL 15.71875 0 \nz\n\" id=\"LiberationSans-114\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(133.309688 36.65625)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-119\"/>\n       <use x=\"72.216797\" xlink:href=\"#LiberationSans-97\"/>\n       <use x=\"127.832031\" xlink:href=\"#LiberationSans-114\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\"/>\n     <g id=\"text_3\">\n      <!-- einmal -->\n      <defs>\n       <path d=\"M 6.6875 64.0625 \nL 6.6875 72.46875 \nL 15.484375 72.46875 \nL 15.484375 64.0625 \nz\nM 6.6875 0 \nL 6.6875 52.828125 \nL 15.484375 52.828125 \nL 15.484375 0 \nz\n\" id=\"LiberationSans-105\"/>\n       <path d=\"M 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 37.359375 39.71875 39.9375 \nQ 39.15625 42.53125 37.890625 44.109375 \nQ 36.625 45.703125 34.546875 46.359375 \nQ 32.46875 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.921875 \nQ 21.234375 44.828125 19.453125 42.75 \nQ 17.671875 40.671875 16.6875 37.625 \nQ 15.71875 34.578125 15.71875 30.609375 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.75 46.09375 18.265625 47.953125 \nQ 19.78125 49.8125 21.78125 51.09375 \nQ 23.78125 52.390625 26.359375 53.09375 \nQ 28.953125 53.8125 32.375 53.8125 \nQ 36.765625 53.8125 39.9375 52.734375 \nQ 43.109375 51.65625 45.15625 49.40625 \nQ 47.21875 47.171875 48.171875 43.625 \nQ 49.125 40.09375 49.125 35.203125 \nL 49.125 0 \nz\n\" id=\"LiberationSans-110\"/>\n       <path d=\"M 37.5 0 \nL 37.5 33.5 \nQ 37.5 37.359375 37.015625 39.9375 \nQ 36.53125 42.53125 35.375 44.109375 \nQ 34.234375 45.703125 32.375 46.359375 \nQ 30.515625 47.015625 27.828125 47.015625 \nQ 25.046875 47.015625 22.796875 45.921875 \nQ 20.5625 44.828125 18.96875 42.75 \nQ 17.390625 40.671875 16.53125 37.625 \nQ 15.671875 34.578125 15.671875 30.609375 \nL 15.671875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.65625 46.09375 18.015625 47.953125 \nQ 19.390625 49.8125 21.21875 51.09375 \nQ 23.046875 52.390625 25.40625 53.09375 \nQ 27.78125 53.8125 30.90625 53.8125 \nQ 36.921875 53.8125 40.40625 51.421875 \nQ 43.890625 49.03125 45.265625 43.796875 \nL 45.40625 43.796875 \nQ 46.578125 46.09375 48.046875 47.953125 \nQ 49.515625 49.8125 51.46875 51.09375 \nQ 53.421875 52.390625 55.859375 53.09375 \nQ 58.296875 53.8125 61.421875 53.8125 \nQ 65.4375 53.8125 68.328125 52.734375 \nQ 71.234375 51.65625 73.09375 49.40625 \nQ 74.953125 47.171875 75.828125 43.625 \nQ 76.703125 40.09375 76.703125 35.203125 \nL 76.703125 0 \nL 68.015625 0 \nL 68.015625 33.5 \nQ 68.015625 37.359375 67.53125 39.9375 \nQ 67.046875 42.53125 65.890625 44.109375 \nQ 64.75 45.703125 62.890625 46.359375 \nQ 61.03125 47.015625 58.34375 47.015625 \nQ 55.5625 47.015625 53.3125 45.96875 \nQ 51.078125 44.921875 49.484375 42.875 \nQ 47.90625 40.828125 47.046875 37.75 \nQ 46.1875 34.671875 46.1875 30.609375 \nL 46.1875 0 \nz\n\" id=\"LiberationSans-109\"/>\n       <path d=\"M 6.734375 0 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 0 \nz\n\" id=\"LiberationSans-108\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(192.829688 36.65625)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-101\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-105\"/>\n       <use x=\"77.832031\" xlink:href=\"#LiberationSans-110\"/>\n       <use x=\"133.447266\" xlink:href=\"#LiberationSans-109\"/>\n       <use x=\"216.748047\" xlink:href=\"#LiberationSans-97\"/>\n       <use x=\"272.363281\" xlink:href=\"#LiberationSans-108\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\"/>\n     <g id=\"text_4\">\n      <!-- ein -->\n      <g style=\"fill:#262626;\" transform=\"translate(252.349688 36.65625)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-101\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-105\"/>\n       <use x=\"77.832031\" xlink:href=\"#LiberationSans-110\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\"/>\n     <g id=\"text_5\">\n      <!-- junge -->\n      <defs>\n       <path d=\"M 6.6875 64.0625 \nL 6.6875 72.46875 \nL 15.484375 72.46875 \nL 15.484375 64.0625 \nz\nM 15.484375 -6.546875 \nQ 15.484375 -9.578125 14.96875 -12.15625 \nQ 14.453125 -14.75 13.125 -16.65625 \nQ 11.8125 -18.5625 9.546875 -19.65625 \nQ 7.28125 -20.75 3.765625 -20.75 \nQ 2.09375 -20.75 0.5 -20.65625 \nQ -1.078125 -20.5625 -2.4375 -20.3125 \nL -2.4375 -13.53125 \nQ -1.8125 -13.625 -0.921875 -13.71875 \nQ -0.046875 -13.8125 0.59375 -13.8125 \nQ 2.4375 -13.8125 3.625 -13.328125 \nQ 4.828125 -12.84375 5.515625 -11.796875 \nQ 6.203125 -10.75 6.4375 -9.109375 \nQ 6.6875 -7.46875 6.6875 -5.21875 \nL 6.6875 52.828125 \nL 15.484375 52.828125 \nz\n\" id=\"LiberationSans-106\"/>\n       <path d=\"M 15.328125 52.828125 \nL 15.328125 19.34375 \nQ 15.328125 15.484375 15.890625 12.890625 \nQ 16.453125 10.296875 17.71875 8.703125 \nQ 19 7.125 21.0625 6.46875 \nQ 23.140625 5.8125 26.21875 5.8125 \nQ 29.34375 5.8125 31.859375 6.90625 \nQ 34.375 8.015625 36.15625 10.078125 \nQ 37.9375 12.15625 38.90625 15.203125 \nQ 39.890625 18.265625 39.890625 22.21875 \nL 39.890625 52.828125 \nL 48.6875 52.828125 \nL 48.6875 11.28125 \nQ 48.6875 9.625 48.703125 7.78125 \nQ 48.734375 5.953125 48.78125 4.3125 \nQ 48.828125 2.6875 48.875 1.515625 \nQ 48.921875 0.34375 48.96875 0 \nL 40.671875 0 \nQ 40.625 0.25 40.578125 1.3125 \nQ 40.53125 2.390625 40.453125 3.78125 \nQ 40.375 5.171875 40.328125 6.609375 \nQ 40.28125 8.0625 40.28125 9.03125 \nL 40.140625 9.03125 \nQ 38.875 6.734375 37.359375 4.875 \nQ 35.84375 3.03125 33.84375 1.734375 \nQ 31.84375 0.4375 29.25 -0.265625 \nQ 26.65625 -0.984375 23.25 -0.984375 \nQ 18.84375 -0.984375 15.671875 0.09375 \nQ 12.5 1.171875 10.453125 3.421875 \nQ 8.40625 5.671875 7.453125 9.1875 \nQ 6.5 12.703125 6.5 17.625 \nL 6.5 52.828125 \nz\n\" id=\"LiberationSans-117\"/>\n       <path d=\"M 26.765625 -20.75 \nQ 22.21875 -20.75 18.703125 -19.8125 \nQ 15.1875 -18.890625 12.6875 -17.15625 \nQ 10.203125 -15.4375 8.640625 -13.03125 \nQ 7.078125 -10.640625 6.390625 -7.71875 \nL 15.234375 -6.453125 \nQ 16.109375 -10.109375 19.109375 -12.078125 \nQ 22.125 -14.0625 27 -14.0625 \nQ 29.984375 -14.0625 32.421875 -13.234375 \nQ 34.859375 -12.40625 36.5625 -10.5625 \nQ 38.28125 -8.734375 39.203125 -5.796875 \nQ 40.140625 -2.875 40.140625 1.3125 \nL 40.140625 9.8125 \nL 40.046875 9.8125 \nQ 39.0625 7.8125 37.625 5.984375 \nQ 36.1875 4.15625 34.109375 2.734375 \nQ 32.03125 1.3125 29.296875 0.453125 \nQ 26.5625 -0.390625 23.046875 -0.390625 \nQ 18.015625 -0.390625 14.421875 1.296875 \nQ 10.84375 2.984375 8.5625 6.34375 \nQ 6.296875 9.71875 5.25 14.71875 \nQ 4.203125 19.734375 4.203125 26.3125 \nQ 4.203125 32.671875 5.25 37.75 \nQ 6.296875 42.828125 8.65625 46.359375 \nQ 11.03125 49.90625 14.8125 51.78125 \nQ 18.609375 53.65625 24.03125 53.65625 \nQ 29.640625 53.65625 33.765625 51.09375 \nQ 37.890625 48.53125 40.140625 43.796875 \nL 40.234375 43.796875 \nQ 40.234375 45.015625 40.296875 46.53125 \nQ 40.375 48.046875 40.453125 49.390625 \nQ 40.53125 50.734375 40.625 51.703125 \nQ 40.71875 52.6875 40.828125 52.828125 \nL 49.171875 52.828125 \nQ 49.125 52.390625 49.078125 51.34375 \nQ 49.03125 50.296875 48.96875 48.828125 \nQ 48.921875 47.359375 48.890625 45.578125 \nQ 48.875 43.796875 48.875 41.890625 \nL 48.875 1.515625 \nQ 48.875 -9.578125 43.421875 -15.15625 \nQ 37.984375 -20.75 26.765625 -20.75 \nz\nM 40.140625 26.421875 \nQ 40.140625 31.9375 38.9375 35.859375 \nQ 37.75 39.796875 35.796875 42.28125 \nQ 33.84375 44.78125 31.328125 45.953125 \nQ 28.8125 47.125 26.171875 47.125 \nQ 22.796875 47.125 20.375 45.953125 \nQ 17.96875 44.78125 16.375 42.265625 \nQ 14.796875 39.75 14.03125 35.8125 \nQ 13.28125 31.890625 13.28125 26.421875 \nQ 13.28125 20.703125 14.03125 16.8125 \nQ 14.796875 12.9375 16.359375 10.546875 \nQ 17.921875 8.15625 20.3125 7.125 \nQ 22.703125 6.109375 26.03125 6.109375 \nQ 28.65625 6.109375 31.171875 7.21875 \nQ 33.6875 8.34375 35.6875 10.78125 \nQ 37.703125 13.234375 38.921875 17.09375 \nQ 40.140625 20.953125 40.140625 26.421875 \nz\n\" id=\"LiberationSans-103\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(311.869688 36.65625)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-106\"/>\n       <use x=\"22.216797\" xlink:href=\"#LiberationSans-117\"/>\n       <use x=\"77.832031\" xlink:href=\"#LiberationSans-110\"/>\n       <use x=\"133.447266\" xlink:href=\"#LiberationSans-103\"/>\n       <use x=\"189.0625\" xlink:href=\"#LiberationSans-101\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\"/>\n     <g id=\"text_6\">\n      <!-- . -->\n      <defs>\n       <path d=\"M 9.125 0 \nL 9.125 10.6875 \nL 18.65625 10.6875 \nL 18.65625 0 \nz\n\" id=\"LiberationSans-46\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(371.389688 36.65625)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-46\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\"/>\n     <g id=\"text_7\">\n      <!-- it -->\n      <defs>\n       <path d=\"M 27.046875 0.390625 \nQ 25.046875 -0.140625 22.96875 -0.453125 \nQ 20.90625 -0.78125 18.171875 -0.78125 \nQ 7.625 -0.78125 7.625 11.1875 \nL 7.625 46.4375 \nL 1.515625 46.4375 \nL 1.515625 52.828125 \nL 7.953125 52.828125 \nL 10.546875 64.65625 \nL 16.40625 64.65625 \nL 16.40625 52.828125 \nL 26.171875 52.828125 \nL 26.171875 46.4375 \nL 16.40625 46.4375 \nL 16.40625 13.09375 \nQ 16.40625 9.28125 17.640625 7.734375 \nQ 18.890625 6.203125 21.96875 6.203125 \nQ 23.25 6.203125 24.4375 6.390625 \nQ 25.640625 6.59375 27.046875 6.890625 \nz\n\" id=\"LiberationSans-116\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(29.44375 72.194687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-105\"/>\n       <use x=\"22.216797\" xlink:href=\"#LiberationSans-116\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\"/>\n     <g id=\"text_8\">\n      <!-- was -->\n      <g style=\"fill:#262626;\" transform=\"translate(16.660938 122.024687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-119\"/>\n       <use x=\"72.216797\" xlink:href=\"#LiberationSans-97\"/>\n       <use x=\"127.832031\" xlink:href=\"#LiberationSans-115\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\"/>\n     <g id=\"text_9\">\n      <!-- once -->\n      <defs>\n       <path d=\"M 51.421875 26.46875 \nQ 51.421875 12.59375 45.3125 5.796875 \nQ 39.203125 -0.984375 27.59375 -0.984375 \nQ 22.078125 -0.984375 17.71875 0.671875 \nQ 13.375 2.34375 10.375 5.765625 \nQ 7.375 9.1875 5.78125 14.328125 \nQ 4.203125 19.484375 4.203125 26.46875 \nQ 4.203125 53.8125 27.875 53.8125 \nQ 34.03125 53.8125 38.5 52.09375 \nQ 42.96875 50.390625 45.828125 46.96875 \nQ 48.6875 43.5625 50.046875 38.421875 \nQ 51.421875 33.296875 51.421875 26.46875 \nz\nM 42.1875 26.46875 \nQ 42.1875 32.625 41.234375 36.625 \nQ 40.28125 40.625 38.453125 43.015625 \nQ 36.625 45.40625 33.984375 46.359375 \nQ 31.34375 47.3125 28.03125 47.3125 \nQ 24.65625 47.3125 21.9375 46.3125 \nQ 19.234375 45.3125 17.328125 42.890625 \nQ 15.4375 40.484375 14.421875 36.46875 \nQ 13.421875 32.46875 13.421875 26.46875 \nQ 13.421875 20.3125 14.5 16.28125 \nQ 15.578125 12.25 17.453125 9.859375 \nQ 19.34375 7.46875 21.90625 6.484375 \nQ 24.46875 5.515625 27.484375 5.515625 \nQ 30.859375 5.515625 33.59375 6.46875 \nQ 36.328125 7.421875 38.234375 9.8125 \nQ 40.140625 12.203125 41.15625 16.25 \nQ 42.1875 20.3125 42.1875 26.46875 \nz\n\" id=\"LiberationSans-111\"/>\n       <path d=\"M 13.421875 26.65625 \nQ 13.421875 22.125 14.078125 18.3125 \nQ 14.75 14.5 16.3125 11.734375 \nQ 17.875 8.984375 20.4375 7.46875 \nQ 23 5.953125 26.765625 5.953125 \nQ 31.453125 5.953125 34.59375 8.484375 \nQ 37.75 11.03125 38.484375 16.3125 \nL 47.359375 15.71875 \nQ 46.921875 12.453125 45.453125 9.421875 \nQ 44 6.390625 41.484375 4.09375 \nQ 38.96875 1.8125 35.34375 0.40625 \nQ 31.734375 -0.984375 27 -0.984375 \nQ 20.796875 -0.984375 16.453125 1.109375 \nQ 12.109375 3.21875 9.390625 6.90625 \nQ 6.6875 10.59375 5.46875 15.59375 \nQ 4.25 20.609375 4.25 26.46875 \nQ 4.25 31.78125 5.125 35.859375 \nQ 6 39.9375 7.59375 42.984375 \nQ 9.1875 46.046875 11.328125 48.125 \nQ 13.484375 50.203125 15.984375 51.4375 \nQ 18.5 52.6875 21.28125 53.25 \nQ 24.078125 53.8125 26.90625 53.8125 \nQ 31.34375 53.8125 34.8125 52.59375 \nQ 38.28125 51.375 40.796875 49.25 \nQ 43.3125 47.125 44.875 44.234375 \nQ 46.4375 41.359375 47.078125 38.03125 \nL 38.03125 37.359375 \nQ 37.359375 41.75 34.5625 44.328125 \nQ 31.78125 46.921875 26.65625 46.921875 \nQ 22.90625 46.921875 20.390625 45.671875 \nQ 17.875 44.4375 16.3125 41.921875 \nQ 14.75 39.40625 14.078125 35.59375 \nQ 13.421875 31.78125 13.421875 26.65625 \nz\n\" id=\"LiberationSans-99\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(12.760938 171.854687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-111\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-110\"/>\n       <use x=\"111.230469\" xlink:href=\"#LiberationSans-99\"/>\n       <use x=\"161.230469\" xlink:href=\"#LiberationSans-101\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\"/>\n     <g id=\"text_10\">\n      <!-- a -->\n      <g style=\"fill:#262626;\" transform=\"translate(28.882813 221.684687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-97\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\"/>\n     <g id=\"text_11\">\n      <!-- young -->\n      <defs>\n       <path d=\"M 29.5 0 \nQ 27.640625 -4.78125 25.703125 -8.609375 \nQ 23.78125 -12.453125 21.390625 -15.15625 \nQ 19 -17.875 16.0625 -19.3125 \nQ 13.140625 -20.75 9.328125 -20.75 \nQ 7.671875 -20.75 6.25 -20.65625 \nQ 4.828125 -20.5625 3.265625 -20.21875 \nL 3.265625 -13.625 \nQ 4.203125 -13.765625 5.375 -13.84375 \nQ 6.546875 -13.921875 7.375 -13.921875 \nQ 11.234375 -13.921875 14.546875 -11.03125 \nQ 17.875 -8.15625 20.359375 -1.859375 \nL 21.1875 0.25 \nL 0.25 52.828125 \nL 9.625 52.828125 \nL 20.75 23.640625 \nQ 21.234375 22.3125 21.984375 20.109375 \nQ 22.75 17.921875 23.5 15.71875 \nQ 24.265625 13.53125 24.84375 11.765625 \nQ 25.4375 10.015625 25.53125 9.578125 \nQ 25.6875 10.109375 26.25 11.6875 \nQ 26.8125 13.28125 27.515625 15.234375 \nQ 28.21875 17.1875 28.953125 19.1875 \nQ 29.6875 21.1875 30.171875 22.65625 \nL 40.53125 52.828125 \nL 49.8125 52.828125 \nz\n\" id=\"LiberationSans-121\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 271.514687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-121\"/>\n       <use x=\"50\" xlink:href=\"#LiberationSans-111\"/>\n       <use x=\"105.615234\" xlink:href=\"#LiberationSans-117\"/>\n       <use x=\"161.230469\" xlink:href=\"#LiberationSans-110\"/>\n       <use x=\"216.845703\" xlink:href=\"#LiberationSans-103\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\"/>\n     <g id=\"text_12\">\n      <!-- . -->\n      <g style=\"fill:#262626;\" transform=\"translate(31.665625 321.344687)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-46\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 41.44375 43.65625 \nL 41.44375 93.48625 \nL 100.96375 93.48625 \nL 100.96375 43.65625 \nL 41.44375 43.65625 \nz\n\" style=\"fill:#58a1cf;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 100.96375 43.65625 \nL 100.96375 93.48625 \nL 160.48375 93.48625 \nL 160.48375 43.65625 \nL 100.96375 43.65625 \nz\n\" style=\"fill:#57a0ce;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 160.48375 43.65625 \nL 160.48375 93.48625 \nL 220.00375 93.48625 \nL 220.00375 43.65625 \nL 160.48375 43.65625 \nz\n\" style=\"fill:#1966ad;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 220.00375 43.65625 \nL 220.00375 93.48625 \nL 279.52375 93.48625 \nL 279.52375 43.65625 \nL 220.00375 43.65625 \nz\n\" style=\"fill:#083370;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 279.52375 43.65625 \nL 279.52375 93.48625 \nL 339.04375 93.48625 \nL 339.04375 43.65625 \nL 279.52375 43.65625 \nz\n\" style=\"fill:#084082;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 339.04375 43.65625 \nL 339.04375 93.48625 \nL 398.56375 93.48625 \nL 398.56375 43.65625 \nL 339.04375 43.65625 \nz\n\" style=\"fill:#083370;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 41.44375 93.48625 \nL 41.44375 143.31625 \nL 100.96375 143.31625 \nL 100.96375 93.48625 \nL 41.44375 93.48625 \nz\n\" style=\"fill:#0a539e;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 100.96375 93.48625 \nL 100.96375 143.31625 \nL 160.48375 143.31625 \nL 160.48375 93.48625 \nL 100.96375 93.48625 \nz\n\" style=\"fill:#7ab6d9;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 160.48375 93.48625 \nL 160.48375 143.31625 \nL 220.00375 143.31625 \nL 220.00375 93.48625 \nL 160.48375 93.48625 \nz\n\" style=\"fill:#2777b8;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 220.00375 93.48625 \nL 220.00375 143.31625 \nL 279.52375 143.31625 \nL 279.52375 93.48625 \nL 220.00375 93.48625 \nz\n\" style=\"fill:#083d7f;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 279.52375 93.48625 \nL 279.52375 143.31625 \nL 339.04375 143.31625 \nL 339.04375 93.48625 \nL 279.52375 93.48625 \nz\n\" style=\"fill:#125da6;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 339.04375 93.48625 \nL 339.04375 143.31625 \nL 398.56375 143.31625 \nL 398.56375 93.48625 \nL 339.04375 93.48625 \nz\n\" style=\"fill:#08326e;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 41.44375 143.31625 \nL 41.44375 193.14625 \nL 100.96375 193.14625 \nL 100.96375 143.31625 \nL 41.44375 143.31625 \nz\n\" style=\"fill:#08316d;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 100.96375 143.31625 \nL 100.96375 193.14625 \nL 160.48375 193.14625 \nL 160.48375 143.31625 \nL 100.96375 143.31625 \nz\n\" style=\"fill:#083c7d;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 160.48375 143.31625 \nL 160.48375 193.14625 \nL 220.00375 193.14625 \nL 220.00375 143.31625 \nL 160.48375 143.31625 \nz\n\" style=\"fill:#f7fbff;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 220.00375 143.31625 \nL 220.00375 193.14625 \nL 279.52375 193.14625 \nL 279.52375 143.31625 \nL 220.00375 143.31625 \nz\n\" style=\"fill:#083e81;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 279.52375 143.31625 \nL 279.52375 193.14625 \nL 339.04375 193.14625 \nL 339.04375 143.31625 \nL 279.52375 143.31625 \nz\n\" style=\"fill:#084184;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 339.04375 143.31625 \nL 339.04375 193.14625 \nL 398.56375 193.14625 \nL 398.56375 143.31625 \nL 339.04375 143.31625 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 41.44375 193.14625 \nL 41.44375 242.97625 \nL 100.96375 242.97625 \nL 100.96375 193.14625 \nL 41.44375 193.14625 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 100.96375 193.14625 \nL 100.96375 242.97625 \nL 160.48375 242.97625 \nL 160.48375 193.14625 \nL 100.96375 193.14625 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 160.48375 193.14625 \nL 160.48375 242.97625 \nL 220.00375 242.97625 \nL 220.00375 193.14625 \nL 160.48375 193.14625 \nz\n\" style=\"fill:#08468b;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 220.00375 193.14625 \nL 220.00375 242.97625 \nL 279.52375 242.97625 \nL 279.52375 193.14625 \nL 220.00375 193.14625 \nz\n\" style=\"fill:#2474b7;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 279.52375 193.14625 \nL 279.52375 242.97625 \nL 339.04375 242.97625 \nL 339.04375 193.14625 \nL 279.52375 193.14625 \nz\n\" style=\"fill:#d1e2f3;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 339.04375 193.14625 \nL 339.04375 242.97625 \nL 398.56375 242.97625 \nL 398.56375 193.14625 \nL 339.04375 193.14625 \nz\n\" style=\"fill:#083573;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 41.44375 242.97625 \nL 41.44375 292.80625 \nL 100.96375 292.80625 \nL 100.96375 242.97625 \nL 41.44375 242.97625 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 100.96375 242.97625 \nL 100.96375 292.80625 \nL 160.48375 292.80625 \nL 160.48375 242.97625 \nL 100.96375 242.97625 \nz\n\" style=\"fill:#08326e;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 160.48375 242.97625 \nL 160.48375 292.80625 \nL 220.00375 292.80625 \nL 220.00375 242.97625 \nL 160.48375 242.97625 \nz\n\" style=\"fill:#083d7f;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 220.00375 242.97625 \nL 220.00375 292.80625 \nL 279.52375 292.80625 \nL 279.52375 242.97625 \nL 220.00375 242.97625 \nz\n\" style=\"fill:#0d57a1;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 279.52375 242.97625 \nL 279.52375 292.80625 \nL 339.04375 292.80625 \nL 339.04375 242.97625 \nL 279.52375 242.97625 \nz\n\" style=\"fill:#e0ecf8;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 339.04375 242.97625 \nL 339.04375 292.80625 \nL 398.56375 292.80625 \nL 398.56375 242.97625 \nL 339.04375 242.97625 \nz\n\" style=\"fill:#08478d;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 41.44375 292.80625 \nL 41.44375 342.63625 \nL 100.96375 342.63625 \nL 100.96375 292.80625 \nL 41.44375 292.80625 \nz\n\" style=\"fill:#08316d;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 100.96375 292.80625 \nL 100.96375 342.63625 \nL 160.48375 342.63625 \nL 160.48375 292.80625 \nL 100.96375 292.80625 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 160.48375 292.80625 \nL 160.48375 342.63625 \nL 220.00375 342.63625 \nL 220.00375 292.80625 \nL 160.48375 292.80625 \nz\n\" style=\"fill:#083573;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 220.00375 292.80625 \nL 220.00375 342.63625 \nL 279.52375 342.63625 \nL 279.52375 292.80625 \nL 220.00375 292.80625 \nz\n\" style=\"fill:#083573;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 279.52375 292.80625 \nL 279.52375 342.63625 \nL 339.04375 342.63625 \nL 339.04375 292.80625 \nL 279.52375 292.80625 \nz\n\" style=\"fill:#0c56a0;\"/>\n    <path clip-path=\"url(#p3905826b0c)\" d=\"M 339.04375 292.80625 \nL 339.04375 342.63625 \nL 398.56375 342.63625 \nL 398.56375 292.80625 \nL 339.04375 292.80625 \nz\n\" style=\"fill:#f5f9fe;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 41.44375 342.63625 \nL 41.44375 43.65625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 398.56375 342.63625 \nL 398.56375 43.65625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 41.44375 342.63625 \nL 398.56375 342.63625 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 41.44375 43.65625 \nL 398.56375 43.65625 \n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pa033e0890c)\" d=\"M 420.88375 342.63625 \nL 420.88375 341.468359 \nL 420.88375 44.824141 \nL 420.88375 43.65625 \nL 435.83275 43.65625 \nL 435.83275 44.824141 \nL 435.83275 341.468359 \nL 435.83275 342.63625 \nz\n\" style=\"fill:#eaeaf2;stroke:#eaeaf2;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\"/>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\"/>\n     <g id=\"text_13\">\n      <!-- 0.1 -->\n      <defs>\n       <path d=\"M 51.703125 34.421875 \nQ 51.703125 24.515625 49.828125 17.75 \nQ 47.953125 10.984375 44.703125 6.8125 \nQ 41.453125 2.640625 37.0625 0.828125 \nQ 32.671875 -0.984375 27.6875 -0.984375 \nQ 22.65625 -0.984375 18.3125 0.828125 \nQ 13.96875 2.640625 10.765625 6.78125 \nQ 7.5625 10.9375 5.734375 17.703125 \nQ 3.90625 24.46875 3.90625 34.421875 \nQ 3.90625 44.828125 5.734375 51.640625 \nQ 7.5625 58.453125 10.78125 62.5 \nQ 14.015625 66.546875 18.40625 68.1875 \nQ 22.796875 69.828125 27.984375 69.828125 \nQ 32.90625 69.828125 37.21875 68.1875 \nQ 41.546875 66.546875 44.765625 62.5 \nQ 48 58.453125 49.84375 51.640625 \nQ 51.703125 44.828125 51.703125 34.421875 \nz\nM 42.78125 34.421875 \nQ 42.78125 42.625 41.796875 48.0625 \nQ 40.828125 53.515625 38.921875 56.765625 \nQ 37.015625 60.015625 34.25 61.359375 \nQ 31.5 62.703125 27.984375 62.703125 \nQ 24.265625 62.703125 21.4375 61.328125 \nQ 18.609375 59.96875 16.671875 56.71875 \nQ 14.75 53.46875 13.765625 48.015625 \nQ 12.796875 42.578125 12.796875 34.421875 \nQ 12.796875 26.515625 13.796875 21.09375 \nQ 14.796875 15.671875 16.71875 12.375 \nQ 18.65625 9.078125 21.4375 7.640625 \nQ 24.21875 6.203125 27.78125 6.203125 \nQ 31.25 6.203125 34.03125 7.640625 \nQ 36.8125 9.078125 38.734375 12.375 \nQ 40.671875 15.671875 41.71875 21.09375 \nQ 42.78125 26.515625 42.78125 34.421875 \nz\n\" id=\"LiberationSans-48\"/>\n       <path d=\"M 7.625 0 \nL 7.625 7.46875 \nL 25.140625 7.46875 \nL 25.140625 60.40625 \nL 9.625 49.3125 \nL 9.625 57.625 \nL 25.875 68.796875 \nL 33.984375 68.796875 \nL 33.984375 7.46875 \nL 50.734375 7.46875 \nL 50.734375 0 \nz\n\" id=\"LiberationSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 311.297154)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\"/>\n     <g id=\"text_14\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 5.03125 0 \nL 5.03125 6.203125 \nQ 7.515625 11.921875 11.109375 16.28125 \nQ 14.703125 20.65625 18.65625 24.1875 \nQ 22.609375 27.734375 26.484375 30.765625 \nQ 30.375 33.796875 33.5 36.8125 \nQ 36.625 39.84375 38.546875 43.15625 \nQ 40.484375 46.484375 40.484375 50.6875 \nQ 40.484375 53.609375 39.59375 55.828125 \nQ 38.71875 58.0625 37.0625 59.5625 \nQ 35.40625 61.078125 33.078125 61.828125 \nQ 30.765625 62.59375 27.9375 62.59375 \nQ 25.296875 62.59375 22.96875 61.859375 \nQ 20.65625 61.140625 18.84375 59.671875 \nQ 17.046875 58.203125 15.890625 56.03125 \nQ 14.75 53.859375 14.40625 50.984375 \nL 5.421875 51.8125 \nQ 5.859375 55.515625 7.46875 58.78125 \nQ 9.078125 62.0625 11.90625 64.53125 \nQ 14.75 67 18.71875 68.40625 \nQ 22.703125 69.828125 27.9375 69.828125 \nQ 33.0625 69.828125 37.0625 68.609375 \nQ 41.0625 67.390625 43.8125 64.984375 \nQ 46.578125 62.59375 48.046875 59.078125 \nQ 49.515625 55.5625 49.515625 50.984375 \nQ 49.515625 47.515625 48.265625 44.390625 \nQ 47.015625 41.265625 44.9375 38.421875 \nQ 42.875 35.59375 40.140625 32.953125 \nQ 37.40625 30.328125 34.421875 27.8125 \nQ 31.453125 25.296875 28.421875 22.828125 \nQ 25.390625 20.359375 22.71875 17.859375 \nQ 20.0625 15.375 17.96875 12.8125 \nQ 15.875 10.25 14.703125 7.46875 \nL 50.59375 7.46875 \nL 50.59375 0 \nz\n\" id=\"LiberationSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 275.468022)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_15\"/>\n     <g id=\"text_15\">\n      <!-- 0.3 -->\n      <defs>\n       <path d=\"M 51.21875 19 \nQ 51.21875 14.265625 49.671875 10.546875 \nQ 48.140625 6.84375 45.1875 4.265625 \nQ 42.234375 1.703125 37.859375 0.359375 \nQ 33.5 -0.984375 27.875 -0.984375 \nQ 21.484375 -0.984375 17.109375 0.609375 \nQ 12.75 2.203125 9.90625 4.8125 \nQ 7.078125 7.421875 5.65625 10.765625 \nQ 4.25 14.109375 3.8125 17.671875 \nL 12.890625 18.5 \nQ 13.28125 15.765625 14.328125 13.515625 \nQ 15.375 11.28125 17.1875 9.671875 \nQ 19 8.0625 21.625 7.171875 \nQ 24.265625 6.296875 27.875 6.296875 \nQ 34.515625 6.296875 38.296875 9.5625 \nQ 42.09375 12.84375 42.09375 19.28125 \nQ 42.09375 23.09375 40.40625 25.40625 \nQ 38.71875 27.734375 36.203125 29.03125 \nQ 33.6875 30.328125 30.734375 30.765625 \nQ 27.78125 31.203125 25.296875 31.203125 \nL 20.3125 31.203125 \nL 20.3125 38.8125 \nL 25.09375 38.8125 \nQ 27.59375 38.8125 30.265625 39.328125 \nQ 32.953125 39.84375 35.171875 41.1875 \nQ 37.40625 42.53125 38.84375 44.828125 \nQ 40.28125 47.125 40.28125 50.6875 \nQ 40.28125 56.203125 37.03125 59.390625 \nQ 33.796875 62.59375 27.390625 62.59375 \nQ 21.578125 62.59375 17.984375 59.609375 \nQ 14.40625 56.640625 13.8125 51.21875 \nL 4.984375 51.90625 \nQ 5.515625 56.453125 7.46875 59.8125 \nQ 9.421875 63.1875 12.421875 65.40625 \nQ 15.4375 67.625 19.28125 68.71875 \nQ 23.140625 69.828125 27.484375 69.828125 \nQ 33.25 69.828125 37.390625 68.375 \nQ 41.546875 66.9375 44.1875 64.46875 \nQ 46.828125 62.015625 48.0625 58.6875 \nQ 49.3125 55.375 49.3125 51.609375 \nQ 49.3125 48.578125 48.484375 45.9375 \nQ 47.65625 43.3125 45.890625 41.203125 \nQ 44.140625 39.109375 41.421875 37.59375 \nQ 38.71875 36.078125 34.90625 35.296875 \nL 34.90625 35.109375 \nQ 39.0625 34.671875 42.140625 33.21875 \nQ 45.21875 31.78125 47.21875 29.625 \nQ 49.21875 27.484375 50.21875 24.75 \nQ 51.21875 22.015625 51.21875 19 \nz\n\" id=\"LiberationSans-51\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 239.638889)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_16\"/>\n     <g id=\"text_16\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 43.015625 15.578125 \nL 43.015625 0 \nL 34.71875 0 \nL 34.71875 15.578125 \nL 2.296875 15.578125 \nL 2.296875 22.40625 \nL 33.796875 68.796875 \nL 43.015625 68.796875 \nL 43.015625 22.515625 \nL 52.6875 22.515625 \nL 52.6875 15.578125 \nz\nM 34.71875 58.890625 \nQ 34.625 58.640625 34.234375 57.9375 \nQ 33.84375 57.234375 33.34375 56.34375 \nQ 32.859375 55.46875 32.34375 54.5625 \nQ 31.84375 53.65625 31.453125 53.078125 \nL 13.8125 27.09375 \nQ 13.578125 26.703125 13.109375 26.0625 \nQ 12.640625 25.4375 12.15625 24.78125 \nQ 11.671875 24.125 11.171875 23.484375 \nQ 10.6875 22.859375 10.40625 22.515625 \nL 34.71875 22.515625 \nz\n\" id=\"LiberationSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 203.809756)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_17\"/>\n     <g id=\"text_17\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 51.421875 22.40625 \nQ 51.421875 17.234375 49.859375 12.9375 \nQ 48.296875 8.640625 45.21875 5.53125 \nQ 42.140625 2.4375 37.578125 0.71875 \nQ 33.015625 -0.984375 27 -0.984375 \nQ 21.578125 -0.984375 17.546875 0.28125 \nQ 13.53125 1.5625 10.734375 3.78125 \nQ 7.953125 6 6.3125 8.984375 \nQ 4.6875 11.96875 4 15.375 \nL 12.890625 16.40625 \nQ 13.421875 14.453125 14.390625 12.625 \nQ 15.375 10.796875 17.0625 9.34375 \nQ 18.75 7.90625 21.21875 7.046875 \nQ 23.6875 6.203125 27.203125 6.203125 \nQ 30.609375 6.203125 33.390625 7.25 \nQ 36.1875 8.296875 38.15625 10.34375 \nQ 40.140625 12.40625 41.203125 15.375 \nQ 42.28125 18.359375 42.28125 22.21875 \nQ 42.28125 25.390625 41.25 28.046875 \nQ 40.234375 30.71875 38.328125 32.640625 \nQ 36.421875 34.578125 33.65625 35.640625 \nQ 30.90625 36.71875 27.390625 36.71875 \nQ 25.203125 36.71875 23.34375 36.328125 \nQ 21.484375 35.9375 19.890625 35.25 \nQ 18.3125 34.578125 17.015625 33.671875 \nQ 15.71875 32.765625 14.59375 31.78125 \nL 6 31.78125 \nL 8.296875 68.796875 \nL 47.40625 68.796875 \nL 47.40625 61.328125 \nL 16.3125 61.328125 \nL 14.984375 39.5 \nQ 17.328125 41.3125 20.84375 42.59375 \nQ 24.359375 43.890625 29.203125 43.890625 \nQ 34.328125 43.890625 38.421875 42.328125 \nQ 42.53125 40.765625 45.40625 37.90625 \nQ 48.296875 35.0625 49.859375 31.109375 \nQ 51.421875 27.15625 51.421875 22.40625 \nz\n\" id=\"LiberationSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 167.980624)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_18\"/>\n     <g id=\"text_18\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 51.21875 22.515625 \nQ 51.21875 17.328125 49.78125 13 \nQ 48.34375 8.6875 45.53125 5.578125 \nQ 42.71875 2.484375 38.5625 0.75 \nQ 34.421875 -0.984375 29 -0.984375 \nQ 23 -0.984375 18.5 1.3125 \nQ 14.015625 3.609375 11.03125 7.921875 \nQ 8.0625 12.25 6.5625 18.53125 \nQ 5.078125 24.8125 5.078125 32.8125 \nQ 5.078125 42 6.765625 48.921875 \nQ 8.453125 55.859375 11.625 60.5 \nQ 14.796875 65.140625 19.359375 67.484375 \nQ 23.921875 69.828125 29.6875 69.828125 \nQ 33.203125 69.828125 36.28125 69.09375 \nQ 39.359375 68.359375 41.875 66.71875 \nQ 44.390625 65.09375 46.28125 62.40625 \nQ 48.1875 59.71875 49.3125 55.8125 \nL 40.921875 54.296875 \nQ 39.546875 58.734375 36.546875 60.71875 \nQ 33.546875 62.703125 29.59375 62.703125 \nQ 25.984375 62.703125 23.046875 60.984375 \nQ 20.125 59.28125 18.0625 55.875 \nQ 16.015625 52.484375 14.90625 47.359375 \nQ 13.8125 42.234375 13.8125 35.40625 \nQ 16.21875 39.84375 20.5625 42.15625 \nQ 24.90625 44.484375 30.515625 44.484375 \nQ 35.203125 44.484375 39.015625 42.96875 \nQ 42.828125 41.453125 45.53125 38.59375 \nQ 48.25 35.75 49.734375 31.671875 \nQ 51.21875 27.59375 51.21875 22.515625 \nz\nM 42.28125 22.125 \nQ 42.28125 25.6875 41.40625 28.5625 \nQ 40.53125 31.453125 38.765625 33.46875 \nQ 37.015625 35.5 34.421875 36.59375 \nQ 31.84375 37.703125 28.421875 37.703125 \nQ 26.03125 37.703125 23.578125 36.984375 \nQ 21.140625 36.28125 19.15625 34.6875 \nQ 17.1875 33.109375 15.9375 30.515625 \nQ 14.703125 27.9375 14.703125 24.21875 \nQ 14.703125 20.40625 15.671875 17.109375 \nQ 16.65625 13.8125 18.484375 11.375 \nQ 20.3125 8.9375 22.890625 7.515625 \nQ 25.484375 6.109375 28.71875 6.109375 \nQ 31.890625 6.109375 34.40625 7.203125 \nQ 36.921875 8.296875 38.671875 10.375 \nQ 40.4375 12.453125 41.359375 15.421875 \nQ 42.28125 18.40625 42.28125 22.125 \nz\n\" id=\"LiberationSans-54\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 132.151491)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_19\"/>\n     <g id=\"text_19\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 50.59375 61.671875 \nQ 45.40625 53.765625 41.0625 46.453125 \nQ 36.71875 39.15625 33.59375 31.75 \nQ 30.46875 24.359375 28.734375 16.578125 \nQ 27 8.796875 27 0 \nL 17.828125 0 \nQ 17.828125 8.25 19.78125 16.1875 \nQ 21.734375 24.125 25.046875 31.765625 \nQ 28.375 39.40625 32.765625 46.78125 \nQ 37.15625 54.15625 42.09375 61.328125 \nL 5.125 61.328125 \nL 5.125 68.796875 \nL 50.59375 68.796875 \nz\n\" id=\"LiberationSans-55\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 96.322358)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_14\">\n     <g id=\"line2d_20\"/>\n     <g id=\"text_20\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 51.265625 19.1875 \nQ 51.265625 14.796875 49.875 11.109375 \nQ 48.484375 7.421875 45.625 4.734375 \nQ 42.78125 2.046875 38.328125 0.53125 \nQ 33.890625 -0.984375 27.828125 -0.984375 \nQ 21.78125 -0.984375 17.359375 0.53125 \nQ 12.9375 2.046875 10.03125 4.703125 \nQ 7.125 7.375 5.734375 11.0625 \nQ 4.34375 14.75 4.34375 19.09375 \nQ 4.34375 22.859375 5.484375 25.78125 \nQ 6.640625 28.71875 8.5625 30.828125 \nQ 10.5 32.953125 12.96875 34.25 \nQ 15.4375 35.546875 18.0625 35.984375 \nL 18.0625 36.1875 \nQ 15.1875 36.859375 12.90625 38.375 \nQ 10.640625 39.890625 9.09375 42.015625 \nQ 7.5625 44.140625 6.75 46.71875 \nQ 5.953125 49.3125 5.953125 52.203125 \nQ 5.953125 55.8125 7.34375 59 \nQ 8.734375 62.203125 11.46875 64.625 \nQ 14.203125 67.046875 18.25 68.4375 \nQ 22.3125 69.828125 27.640625 69.828125 \nQ 33.25 69.828125 37.375 68.40625 \nQ 41.5 67 44.203125 64.578125 \nQ 46.921875 62.15625 48.234375 58.9375 \nQ 49.5625 55.71875 49.5625 52.09375 \nQ 49.5625 49.265625 48.75 46.671875 \nQ 47.953125 44.09375 46.40625 41.96875 \nQ 44.875 39.84375 42.59375 38.34375 \nQ 40.328125 36.859375 37.359375 36.28125 \nL 37.359375 36.078125 \nQ 40.328125 35.59375 42.859375 34.296875 \nQ 45.40625 33.015625 47.265625 30.890625 \nQ 49.125 28.765625 50.1875 25.828125 \nQ 51.265625 22.90625 51.265625 19.1875 \nz\nM 40.4375 51.609375 \nQ 40.4375 54.203125 39.765625 56.34375 \nQ 39.109375 58.5 37.59375 60.03125 \nQ 36.078125 61.578125 33.640625 62.421875 \nQ 31.203125 63.28125 27.640625 63.28125 \nQ 24.171875 63.28125 21.78125 62.421875 \nQ 19.390625 61.578125 17.84375 60.03125 \nQ 16.3125 58.5 15.625 56.34375 \nQ 14.9375 54.203125 14.9375 51.609375 \nQ 14.9375 49.5625 15.46875 47.40625 \nQ 16.015625 45.265625 17.421875 43.5 \nQ 18.84375 41.75 21.328125 40.625 \nQ 23.828125 39.5 27.734375 39.5 \nQ 31.890625 39.5 34.40625 40.625 \nQ 36.921875 41.75 38.25 43.5 \nQ 39.59375 45.265625 40.015625 47.40625 \nQ 40.4375 49.5625 40.4375 51.609375 \nz\nM 42.140625 20.015625 \nQ 42.140625 22.515625 41.453125 24.828125 \nQ 40.765625 27.15625 39.109375 28.9375 \nQ 37.453125 30.71875 34.640625 31.8125 \nQ 31.84375 32.90625 27.640625 32.90625 \nQ 23.78125 32.90625 21.0625 31.8125 \nQ 18.359375 30.71875 16.671875 28.90625 \nQ 14.984375 27.09375 14.203125 24.71875 \nQ 13.421875 22.359375 13.421875 19.828125 \nQ 13.421875 16.65625 14.203125 14.03125 \nQ 14.984375 11.421875 16.6875 9.546875 \nQ 18.40625 7.671875 21.1875 6.640625 \nQ 23.96875 5.609375 27.9375 5.609375 \nQ 31.9375 5.609375 34.671875 6.640625 \nQ 37.40625 7.671875 39.0625 9.546875 \nQ 40.71875 11.421875 41.421875 14.078125 \nQ 42.140625 16.75 42.140625 20.015625 \nz\n\" id=\"LiberationSans-56\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(442.83275 60.493225)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <image height=\"299\" id=\"image711f0363c4\" transform=\"scale(1 -1)translate(0 -299)\" width=\"15\" x=\"421\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAA8AAAErCAYAAAABnNneAAAABHNCSVQICAgIfAhkiAAAAWFJREFUeJztm8GNw0AMA3cNP66c9JX+37ka7AE8GFj+E8ySoqQ1nP33+f7Wzedc+7iLXefam4Al5vu0652CjVUPMxPwIf1salWxPKPMY9XD4GmAzzFvC0ytAmDtzCKYCMasigqmqS2m6oWCVRvgqH0RPA3wSfA7G+AwX3mYVQe5uTcF684qBI6qLTGPVRnmrlVFtcVZ5Ql2NK0Csz1r1QY7MxKsmqpobWt5hsFAYKsZRGcVDQYAM8HuE1fzLC5xTcFOolg1VV4kITMAe7MKVhhhFjcDBI42QMKs7dtaM1DXCsTcbICgwqqpMhtg8xZLwNVlnTBHX+NFfdbObL7GY8wATCaG9/bRnFWeYMndk74DLJaneE0QZxUBe8OdfTf0Qquagnln7jZAAG4WyaTqOjMAT6ougptFMqm6zgzAk6onmdcLU+Xdq2CeCbiZqqZg0Vllfl2bbL3mP3KTgnln9mr7H6/jCEJx9UtRAAAAAElFTkSuQmCC\" y=\"-43\"/>\n   <g id=\"patch_8\">\n    <path d=\"M 420.88375 342.63625 \nL 420.88375 341.468359 \nL 420.88375 44.824141 \nL 420.88375 43.65625 \nL 435.83275 43.65625 \nL 435.83275 44.824141 \nL 435.83275 341.468359 \nL 435.83275 342.63625 \nz\n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3905826b0c\">\n   <rect height=\"298.98\" width=\"357.12\" x=\"41.44375\" y=\"43.65625\"/>\n  </clipPath>\n  <clipPath id=\"pa033e0890c\">\n   <rect height=\"298.98\" width=\"14.949\" x=\"420.88375\" y=\"43.65625\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{}}],"source":["#plot_attention(translator, 'das haus ist klein .')\n","plot_attention(translator, 'es war einmal ein junge .')"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"OFV_KRVGWkRv","executionInfo":{"status":"ok","timestamp":1676017240566,"user_tz":-60,"elapsed":542,"user":{"displayName":"TheQkk LP","userId":"05924923103342954592"}},"outputId":"939aab6b-e3bd-4c13-c9a6-35f218892705"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x396 with 2 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"355.77375pt\" version=\"1.1\" viewBox=\"0 0 464.492125 355.77375\" width=\"464.492125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 355.77375 \nL 464.492125 355.77375 \nL 464.492125 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 42.003125 348.57375 \nL 399.123125 348.57375 \nL 399.123125 49.59375 \nL 42.003125 49.59375 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\"/>\n     <g id=\"text_1\">\n      <!-- ich -->\n      <defs>\n       <path d=\"M 6.6875 64.0625 \nL 6.6875 72.46875 \nL 15.484375 72.46875 \nL 15.484375 64.0625 \nz\nM 6.6875 0 \nL 6.6875 52.828125 \nL 15.484375 52.828125 \nL 15.484375 0 \nz\n\" id=\"LiberationSans-105\"/>\n       <path d=\"M 13.421875 26.65625 \nQ 13.421875 22.125 14.078125 18.3125 \nQ 14.75 14.5 16.3125 11.734375 \nQ 17.875 8.984375 20.4375 7.46875 \nQ 23 5.953125 26.765625 5.953125 \nQ 31.453125 5.953125 34.59375 8.484375 \nQ 37.75 11.03125 38.484375 16.3125 \nL 47.359375 15.71875 \nQ 46.921875 12.453125 45.453125 9.421875 \nQ 44 6.390625 41.484375 4.09375 \nQ 38.96875 1.8125 35.34375 0.40625 \nQ 31.734375 -0.984375 27 -0.984375 \nQ 20.796875 -0.984375 16.453125 1.109375 \nQ 12.109375 3.21875 9.390625 6.90625 \nQ 6.6875 10.59375 5.46875 15.59375 \nQ 4.25 20.609375 4.25 26.46875 \nQ 4.25 31.78125 5.125 35.859375 \nQ 6 39.9375 7.59375 42.984375 \nQ 9.1875 46.046875 11.328125 48.125 \nQ 13.484375 50.203125 15.984375 51.4375 \nQ 18.5 52.6875 21.28125 53.25 \nQ 24.078125 53.8125 26.90625 53.8125 \nQ 31.34375 53.8125 34.8125 52.59375 \nQ 38.28125 51.375 40.796875 49.25 \nQ 43.3125 47.125 44.875 44.234375 \nQ 46.4375 41.359375 47.078125 38.03125 \nL 38.03125 37.359375 \nQ 37.359375 41.75 34.5625 44.328125 \nQ 31.78125 46.921875 26.65625 46.921875 \nQ 22.90625 46.921875 20.390625 45.671875 \nQ 17.875 44.4375 16.3125 41.921875 \nQ 14.75 39.40625 14.078125 35.59375 \nQ 13.421875 31.78125 13.421875 26.65625 \nz\n\" id=\"LiberationSans-99\"/>\n       <path d=\"M 15.484375 43.796875 \nQ 16.9375 46.484375 18.640625 48.359375 \nQ 20.359375 50.25 22.40625 51.46875 \nQ 24.46875 52.6875 26.90625 53.25 \nQ 29.34375 53.8125 32.375 53.8125 \nQ 37.453125 53.8125 40.703125 52.4375 \nQ 43.953125 51.078125 45.828125 48.609375 \nQ 47.703125 46.140625 48.40625 42.71875 \nQ 49.125 39.3125 49.125 35.203125 \nL 49.125 0 \nL 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 36.859375 39.859375 39.390625 \nQ 39.453125 41.9375 38.28125 43.625 \nQ 37.109375 45.3125 34.953125 46.15625 \nQ 32.8125 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.890625 \nQ 21.234375 44.78125 19.453125 42.71875 \nQ 17.671875 40.671875 16.6875 37.734375 \nQ 15.71875 34.8125 15.71875 31.15625 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 72.46875 \nL 15.71875 72.46875 \nL 15.71875 53.609375 \nQ 15.71875 52 15.671875 50.390625 \nQ 15.625 48.78125 15.546875 47.40625 \nQ 15.484375 46.046875 15.421875 45.09375 \nQ 15.375 44.140625 15.328125 43.796875 \nz\n\" id=\"LiberationSans-104\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(80.301063 42.59375)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-105\"/>\n       <use x=\"22.216797\" xlink:href=\"#LiberationSans-99\"/>\n       <use x=\"72.216797\" xlink:href=\"#LiberationSans-104\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\"/>\n     <g id=\"text_2\">\n      <!-- bin -->\n      <defs>\n       <path d=\"M 51.421875 26.65625 \nQ 51.421875 -0.984375 31.984375 -0.984375 \nQ 25.984375 -0.984375 22 1.1875 \nQ 18.015625 3.375 15.53125 8.203125 \nL 15.4375 8.203125 \nQ 15.4375 6.9375 15.359375 5.5625 \nQ 15.28125 4.203125 15.203125 3.03125 \nQ 15.140625 1.859375 15.0625 1.03125 \nQ 14.984375 0.203125 14.9375 0 \nL 6.453125 0 \nQ 6.5 0.4375 6.546875 1.484375 \nQ 6.59375 2.546875 6.640625 4 \nQ 6.6875 5.46875 6.703125 7.21875 \nQ 6.734375 8.984375 6.734375 10.890625 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 51.8125 \nQ 15.53125 50.34375 15.5 49 \nQ 15.484375 47.65625 15.4375 46.625 \nQ 15.375 45.40625 15.328125 44.34375 \nL 15.53125 44.34375 \nQ 17.96875 49.421875 22 51.609375 \nQ 26.03125 53.8125 31.984375 53.8125 \nQ 42 53.8125 46.703125 47.0625 \nQ 51.421875 40.328125 51.421875 26.65625 \nz\nM 42.1875 26.375 \nQ 42.1875 31.84375 41.5 35.75 \nQ 40.828125 39.65625 39.3125 42.15625 \nQ 37.796875 44.671875 35.453125 45.84375 \nQ 33.109375 47.015625 29.734375 47.015625 \nQ 26.265625 47.015625 23.609375 45.890625 \nQ 20.953125 44.78125 19.171875 42.28125 \nQ 17.390625 39.796875 16.453125 35.734375 \nQ 15.53125 31.6875 15.53125 25.828125 \nQ 15.53125 20.171875 16.453125 16.3125 \nQ 17.390625 12.453125 19.171875 10.03125 \nQ 20.953125 7.625 23.578125 6.5625 \nQ 26.21875 5.515625 29.640625 5.515625 \nQ 32.859375 5.515625 35.203125 6.640625 \nQ 37.546875 7.765625 39.109375 10.25 \nQ 40.671875 12.75 41.421875 16.71875 \nQ 42.1875 20.703125 42.1875 26.375 \nz\n\" id=\"LiberationSans-98\"/>\n       <path d=\"M 40.28125 0 \nL 40.28125 33.5 \nQ 40.28125 37.359375 39.71875 39.9375 \nQ 39.15625 42.53125 37.890625 44.109375 \nQ 36.625 45.703125 34.546875 46.359375 \nQ 32.46875 47.015625 29.390625 47.015625 \nQ 26.265625 47.015625 23.75 45.921875 \nQ 21.234375 44.828125 19.453125 42.75 \nQ 17.671875 40.671875 16.6875 37.625 \nQ 15.71875 34.578125 15.71875 30.609375 \nL 15.71875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.75 46.09375 18.265625 47.953125 \nQ 19.78125 49.8125 21.78125 51.09375 \nQ 23.78125 52.390625 26.359375 53.09375 \nQ 28.953125 53.8125 32.375 53.8125 \nQ 36.765625 53.8125 39.9375 52.734375 \nQ 43.109375 51.65625 45.15625 49.40625 \nQ 47.21875 47.171875 48.171875 43.625 \nQ 49.125 40.09375 49.125 35.203125 \nL 49.125 0 \nz\n\" id=\"LiberationSans-110\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(151.725063 42.59375)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-98\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-105\"/>\n       <use x=\"77.832031\" xlink:href=\"#LiberationSans-110\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\"/>\n     <g id=\"text_3\">\n      <!-- ein -->\n      <defs>\n       <path d=\"M 13.484375 24.5625 \nQ 13.484375 20.40625 14.328125 16.90625 \nQ 15.1875 13.421875 16.96875 10.90625 \nQ 18.75 8.40625 21.53125 7 \nQ 24.3125 5.609375 28.21875 5.609375 \nQ 33.9375 5.609375 37.375 7.90625 \nQ 40.828125 10.203125 42.046875 13.71875 \nL 49.75 11.53125 \nQ 48.921875 9.328125 47.4375 7.109375 \nQ 45.953125 4.890625 43.453125 3.09375 \nQ 40.96875 1.3125 37.234375 0.15625 \nQ 33.5 -0.984375 28.21875 -0.984375 \nQ 16.5 -0.984375 10.375 6 \nQ 4.25 12.984375 4.25 26.765625 \nQ 4.25 34.1875 6.09375 39.328125 \nQ 7.953125 44.484375 11.171875 47.703125 \nQ 14.40625 50.921875 18.703125 52.359375 \nQ 23 53.8125 27.875 53.8125 \nQ 34.515625 53.8125 38.984375 51.65625 \nQ 43.453125 49.515625 46.15625 45.71875 \nQ 48.875 41.9375 50.015625 36.8125 \nQ 51.171875 31.6875 51.171875 25.734375 \nL 51.171875 24.5625 \nz\nM 42.09375 31.296875 \nQ 41.359375 39.65625 37.84375 43.484375 \nQ 34.328125 47.3125 27.734375 47.3125 \nQ 25.53125 47.3125 23.109375 46.609375 \nQ 20.703125 45.90625 18.65625 44.09375 \nQ 16.609375 42.28125 15.1875 39.171875 \nQ 13.765625 36.078125 13.578125 31.296875 \nz\n\" id=\"LiberationSans-101\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(223.149063 42.59375)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-101\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-105\"/>\n       <use x=\"77.832031\" xlink:href=\"#LiberationSans-110\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\"/>\n     <g id=\"text_4\">\n      <!-- kartoffel -->\n      <defs>\n       <path d=\"M 39.84375 0 \nL 21.96875 24.125 \nL 15.53125 18.796875 \nL 15.53125 0 \nL 6.734375 0 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 27.203125 \nL 38.71875 52.828125 \nL 49.03125 52.828125 \nL 27.59375 30.125 \nL 50.140625 0 \nz\n\" id=\"LiberationSans-107\"/>\n       <path d=\"M 20.21875 -0.984375 \nQ 12.25 -0.984375 8.25 3.21875 \nQ 4.25 7.421875 4.25 14.75 \nQ 4.25 19.96875 6.21875 23.3125 \nQ 8.203125 26.65625 11.390625 28.5625 \nQ 14.59375 30.46875 18.6875 31.203125 \nQ 22.796875 31.9375 27.046875 32.03125 \nL 38.921875 32.234375 \nL 38.921875 35.109375 \nQ 38.921875 38.375 38.234375 40.671875 \nQ 37.546875 42.96875 36.125 44.375 \nQ 34.71875 45.796875 32.59375 46.453125 \nQ 30.46875 47.125 27.59375 47.125 \nQ 25.046875 47.125 23 46.75 \nQ 20.953125 46.390625 19.4375 45.4375 \nQ 17.921875 44.484375 16.984375 42.84375 \nQ 16.0625 41.21875 15.765625 38.71875 \nL 6.59375 39.546875 \nQ 7.078125 42.671875 8.4375 45.28125 \nQ 9.8125 47.90625 12.328125 49.796875 \nQ 14.84375 51.703125 18.625 52.75 \nQ 22.40625 53.8125 27.78125 53.8125 \nQ 37.75 53.8125 42.765625 49.234375 \nQ 47.796875 44.671875 47.796875 36.03125 \nL 47.796875 13.28125 \nQ 47.796875 9.375 48.828125 7.390625 \nQ 49.859375 5.421875 52.734375 5.421875 \nQ 53.46875 5.421875 54.203125 5.515625 \nQ 54.9375 5.609375 55.609375 5.765625 \nL 55.609375 0.296875 \nQ 53.953125 -0.09375 52.3125 -0.28125 \nQ 50.6875 -0.484375 48.828125 -0.484375 \nQ 46.34375 -0.484375 44.5625 0.171875 \nQ 42.78125 0.828125 41.65625 2.171875 \nQ 40.53125 3.515625 39.9375 5.484375 \nQ 39.359375 7.46875 39.203125 10.109375 \nL 38.921875 10.109375 \nQ 37.5 7.5625 35.8125 5.515625 \nQ 34.125 3.46875 31.875 2.03125 \nQ 29.640625 0.59375 26.78125 -0.1875 \nQ 23.921875 -0.984375 20.21875 -0.984375 \nz\nM 22.21875 5.609375 \nQ 26.421875 5.609375 29.5625 7.140625 \nQ 32.71875 8.6875 34.78125 11.078125 \nQ 36.859375 13.484375 37.890625 16.3125 \nQ 38.921875 19.140625 38.921875 21.734375 \nL 38.921875 26.078125 \nL 29.296875 25.875 \nQ 26.078125 25.828125 23.171875 25.40625 \nQ 20.265625 25 18.0625 23.78125 \nQ 15.875 22.5625 14.578125 20.359375 \nQ 13.28125 18.171875 13.28125 14.59375 \nQ 13.28125 10.296875 15.59375 7.953125 \nQ 17.921875 5.609375 22.21875 5.609375 \nz\n\" id=\"LiberationSans-97\"/>\n       <path d=\"M 6.9375 0 \nL 6.9375 40.53125 \nQ 6.9375 42.1875 6.90625 43.921875 \nQ 6.890625 45.65625 6.828125 47.265625 \nQ 6.78125 48.875 6.734375 50.28125 \nQ 6.6875 51.703125 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 51.703125 15.0625 50.265625 \nQ 15.140625 48.828125 15.203125 47.3125 \nQ 15.28125 45.796875 15.296875 44.40625 \nQ 15.328125 43.015625 15.328125 42.046875 \nL 15.53125 42.046875 \nQ 16.453125 45.0625 17.5 47.28125 \nQ 18.5625 49.515625 19.96875 50.953125 \nQ 21.390625 52.390625 23.34375 53.09375 \nQ 25.296875 53.8125 28.078125 53.8125 \nQ 29.15625 53.8125 30.125 53.640625 \nQ 31.109375 53.46875 31.640625 53.328125 \nL 31.640625 45.265625 \nQ 30.765625 45.515625 29.59375 45.625 \nQ 28.421875 45.75 26.953125 45.75 \nQ 23.921875 45.75 21.796875 44.375 \nQ 19.671875 43.015625 18.328125 40.59375 \nQ 17 38.1875 16.359375 34.84375 \nQ 15.71875 31.5 15.71875 27.546875 \nL 15.71875 0 \nz\n\" id=\"LiberationSans-114\"/>\n       <path d=\"M 27.046875 0.390625 \nQ 25.046875 -0.140625 22.96875 -0.453125 \nQ 20.90625 -0.78125 18.171875 -0.78125 \nQ 7.625 -0.78125 7.625 11.1875 \nL 7.625 46.4375 \nL 1.515625 46.4375 \nL 1.515625 52.828125 \nL 7.953125 52.828125 \nL 10.546875 64.65625 \nL 16.40625 64.65625 \nL 16.40625 52.828125 \nL 26.171875 52.828125 \nL 26.171875 46.4375 \nL 16.40625 46.4375 \nL 16.40625 13.09375 \nQ 16.40625 9.28125 17.640625 7.734375 \nQ 18.890625 6.203125 21.96875 6.203125 \nQ 23.25 6.203125 24.4375 6.390625 \nQ 25.640625 6.59375 27.046875 6.890625 \nz\n\" id=\"LiberationSans-116\"/>\n       <path d=\"M 51.421875 26.46875 \nQ 51.421875 12.59375 45.3125 5.796875 \nQ 39.203125 -0.984375 27.59375 -0.984375 \nQ 22.078125 -0.984375 17.71875 0.671875 \nQ 13.375 2.34375 10.375 5.765625 \nQ 7.375 9.1875 5.78125 14.328125 \nQ 4.203125 19.484375 4.203125 26.46875 \nQ 4.203125 53.8125 27.875 53.8125 \nQ 34.03125 53.8125 38.5 52.09375 \nQ 42.96875 50.390625 45.828125 46.96875 \nQ 48.6875 43.5625 50.046875 38.421875 \nQ 51.421875 33.296875 51.421875 26.46875 \nz\nM 42.1875 26.46875 \nQ 42.1875 32.625 41.234375 36.625 \nQ 40.28125 40.625 38.453125 43.015625 \nQ 36.625 45.40625 33.984375 46.359375 \nQ 31.34375 47.3125 28.03125 47.3125 \nQ 24.65625 47.3125 21.9375 46.3125 \nQ 19.234375 45.3125 17.328125 42.890625 \nQ 15.4375 40.484375 14.421875 36.46875 \nQ 13.421875 32.46875 13.421875 26.46875 \nQ 13.421875 20.3125 14.5 16.28125 \nQ 15.578125 12.25 17.453125 9.859375 \nQ 19.34375 7.46875 21.90625 6.484375 \nQ 24.46875 5.515625 27.484375 5.515625 \nQ 30.859375 5.515625 33.59375 6.46875 \nQ 36.328125 7.421875 38.234375 9.8125 \nQ 40.140625 12.203125 41.15625 16.25 \nQ 42.1875 20.3125 42.1875 26.46875 \nz\n\" id=\"LiberationSans-111\"/>\n       <path d=\"M 17.625 46.4375 \nL 17.625 0 \nL 8.84375 0 \nL 8.84375 46.4375 \nL 1.421875 46.4375 \nL 1.421875 52.828125 \nL 8.84375 52.828125 \nL 8.84375 58.796875 \nQ 8.84375 61.671875 9.375 64.140625 \nQ 9.90625 66.609375 11.34375 68.4375 \nQ 12.796875 70.265625 15.28125 71.3125 \nQ 17.78125 72.359375 21.734375 72.359375 \nQ 23.296875 72.359375 24.96875 72.21875 \nQ 26.65625 72.078125 27.9375 71.78125 \nL 27.9375 65.09375 \nQ 27.09375 65.234375 26 65.359375 \nQ 24.90625 65.484375 24.03125 65.484375 \nQ 22.078125 65.484375 20.828125 64.9375 \nQ 19.578125 64.40625 18.875 63.40625 \nQ 18.171875 62.40625 17.890625 60.9375 \nQ 17.625 59.46875 17.625 57.5625 \nL 17.625 52.828125 \nL 27.9375 52.828125 \nL 27.9375 46.4375 \nz\n\" id=\"LiberationSans-102\"/>\n       <path d=\"M 6.734375 0 \nL 6.734375 72.46875 \nL 15.53125 72.46875 \nL 15.53125 0 \nz\n\" id=\"LiberationSans-108\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(294.573063 42.59375)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-107\"/>\n       <use x=\"50\" xlink:href=\"#LiberationSans-97\"/>\n       <use x=\"105.615234\" xlink:href=\"#LiberationSans-114\"/>\n       <use x=\"138.916016\" xlink:href=\"#LiberationSans-116\"/>\n       <use x=\"166.699219\" xlink:href=\"#LiberationSans-111\"/>\n       <use x=\"222.314453\" xlink:href=\"#LiberationSans-102\"/>\n       <use x=\"248.347656\" xlink:href=\"#LiberationSans-102\"/>\n       <use x=\"276.130859\" xlink:href=\"#LiberationSans-101\"/>\n       <use x=\"331.746094\" xlink:href=\"#LiberationSans-108\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\"/>\n     <g id=\"text_5\">\n      <!-- . -->\n      <defs>\n       <path d=\"M 9.125 0 \nL 9.125 10.6875 \nL 18.65625 10.6875 \nL 18.65625 0 \nz\n\" id=\"LiberationSans-46\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(365.997063 42.59375)rotate(-90)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-46\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\"/>\n     <g id=\"text_6\">\n      <!-- i -->\n      <g style=\"fill:#262626;\" transform=\"translate(32.78125 83.115187)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-105\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\"/>\n     <g id=\"text_7\">\n      <!-- 'm -->\n      <defs>\n       <path d=\"M 12.984375 47.171875 \nL 6.109375 47.171875 \nL 5.078125 68.796875 \nL 14.0625 68.796875 \nz\n\" id=\"LiberationSans-39\"/>\n       <path d=\"M 37.5 0 \nL 37.5 33.5 \nQ 37.5 37.359375 37.015625 39.9375 \nQ 36.53125 42.53125 35.375 44.109375 \nQ 34.234375 45.703125 32.375 46.359375 \nQ 30.515625 47.015625 27.828125 47.015625 \nQ 25.046875 47.015625 22.796875 45.921875 \nQ 20.5625 44.828125 18.96875 42.75 \nQ 17.390625 40.671875 16.53125 37.625 \nQ 15.671875 34.578125 15.671875 30.609375 \nL 15.671875 0 \nL 6.9375 0 \nL 6.9375 41.546875 \nQ 6.9375 43.21875 6.90625 45.046875 \nQ 6.890625 46.875 6.828125 48.5 \nQ 6.78125 50.140625 6.734375 51.3125 \nQ 6.6875 52.484375 6.640625 52.828125 \nL 14.9375 52.828125 \nQ 14.984375 52.59375 15.03125 51.515625 \nQ 15.09375 50.4375 15.15625 49.046875 \nQ 15.234375 47.65625 15.28125 46.21875 \nQ 15.328125 44.78125 15.328125 43.796875 \nL 15.484375 43.796875 \nQ 16.65625 46.09375 18.015625 47.953125 \nQ 19.390625 49.8125 21.21875 51.09375 \nQ 23.046875 52.390625 25.40625 53.09375 \nQ 27.78125 53.8125 30.90625 53.8125 \nQ 36.921875 53.8125 40.40625 51.421875 \nQ 43.890625 49.03125 45.265625 43.796875 \nL 45.40625 43.796875 \nQ 46.578125 46.09375 48.046875 47.953125 \nQ 49.515625 49.8125 51.46875 51.09375 \nQ 53.421875 52.390625 55.859375 53.09375 \nQ 58.296875 53.8125 61.421875 53.8125 \nQ 65.4375 53.8125 68.328125 52.734375 \nQ 71.234375 51.65625 73.09375 49.40625 \nQ 74.953125 47.171875 75.828125 43.625 \nQ 76.703125 40.09375 76.703125 35.203125 \nL 76.703125 0 \nL 68.015625 0 \nL 68.015625 33.5 \nQ 68.015625 37.359375 67.53125 39.9375 \nQ 67.046875 42.53125 65.890625 44.109375 \nQ 64.75 45.703125 62.890625 46.359375 \nQ 61.03125 47.015625 58.34375 47.015625 \nQ 55.5625 47.015625 53.3125 45.96875 \nQ 51.078125 44.921875 49.484375 42.875 \nQ 47.90625 40.828125 47.046875 37.75 \nQ 46.1875 34.671875 46.1875 30.609375 \nL 46.1875 0 \nz\n\" id=\"LiberationSans-109\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(24.764063 142.911187)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-39\"/>\n       <use x=\"19.091797\" xlink:href=\"#LiberationSans-109\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\"/>\n     <g id=\"text_8\">\n      <!-- a -->\n      <g style=\"fill:#262626;\" transform=\"translate(29.442188 202.707187)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-97\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\"/>\n     <g id=\"text_9\">\n      <!-- &lt;unk&gt; -->\n      <defs>\n       <path d=\"M 4.9375 27.875 \nL 4.9375 37.890625 \nL 53.515625 58.296875 \nL 53.515625 50.78125 \nL 11.625 32.90625 \nL 53.515625 14.984375 \nL 53.515625 7.515625 \nz\n\" id=\"LiberationSans-60\"/>\n       <path d=\"M 15.328125 52.828125 \nL 15.328125 19.34375 \nQ 15.328125 15.484375 15.890625 12.890625 \nQ 16.453125 10.296875 17.71875 8.703125 \nQ 19 7.125 21.0625 6.46875 \nQ 23.140625 5.8125 26.21875 5.8125 \nQ 29.34375 5.8125 31.859375 6.90625 \nQ 34.375 8.015625 36.15625 10.078125 \nQ 37.9375 12.15625 38.90625 15.203125 \nQ 39.890625 18.265625 39.890625 22.21875 \nL 39.890625 52.828125 \nL 48.6875 52.828125 \nL 48.6875 11.28125 \nQ 48.6875 9.625 48.703125 7.78125 \nQ 48.734375 5.953125 48.78125 4.3125 \nQ 48.828125 2.6875 48.875 1.515625 \nQ 48.921875 0.34375 48.96875 0 \nL 40.671875 0 \nQ 40.625 0.25 40.578125 1.3125 \nQ 40.53125 2.390625 40.453125 3.78125 \nQ 40.375 5.171875 40.328125 6.609375 \nQ 40.28125 8.0625 40.28125 9.03125 \nL 40.140625 9.03125 \nQ 38.875 6.734375 37.359375 4.875 \nQ 35.84375 3.03125 33.84375 1.734375 \nQ 31.84375 0.4375 29.25 -0.265625 \nQ 26.65625 -0.984375 23.25 -0.984375 \nQ 18.84375 -0.984375 15.671875 0.09375 \nQ 12.5 1.171875 10.453125 3.421875 \nQ 8.40625 5.671875 7.453125 9.1875 \nQ 6.5 12.703125 6.5 17.625 \nL 6.5 52.828125 \nz\n\" id=\"LiberationSans-117\"/>\n       <path d=\"M 4.9375 7.515625 \nL 4.9375 14.984375 \nL 46.828125 32.90625 \nL 4.9375 50.78125 \nL 4.9375 58.296875 \nL 53.515625 37.890625 \nL 53.515625 27.875 \nz\n\" id=\"LiberationSans-62\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 262.503187)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-60\"/>\n       <use x=\"58.398438\" xlink:href=\"#LiberationSans-117\"/>\n       <use x=\"114.013672\" xlink:href=\"#LiberationSans-110\"/>\n       <use x=\"169.628906\" xlink:href=\"#LiberationSans-107\"/>\n       <use x=\"219.628906\" xlink:href=\"#LiberationSans-62\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\"/>\n     <g id=\"text_10\">\n      <!-- . -->\n      <g style=\"fill:#262626;\" transform=\"translate(32.225 322.299188)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-46\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"PolyCollection_1\">\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 42.003125 49.59375 \nL 42.003125 109.38975 \nL 113.427125 109.38975 \nL 113.427125 49.59375 \nL 42.003125 49.59375 \nz\n\" style=\"fill:#f1f7fd;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 113.427125 49.59375 \nL 113.427125 109.38975 \nL 184.851125 109.38975 \nL 184.851125 49.59375 \nL 113.427125 49.59375 \nz\n\" style=\"fill:#1865ac;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 184.851125 49.59375 \nL 184.851125 109.38975 \nL 256.275125 109.38975 \nL 256.275125 49.59375 \nL 184.851125 49.59375 \nz\n\" style=\"fill:#08316d;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 256.275125 49.59375 \nL 256.275125 109.38975 \nL 327.699125 109.38975 \nL 327.699125 49.59375 \nL 256.275125 49.59375 \nz\n\" style=\"fill:#08316d;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 327.699125 49.59375 \nL 327.699125 109.38975 \nL 399.123125 109.38975 \nL 399.123125 49.59375 \nL 327.699125 49.59375 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 42.003125 109.38975 \nL 42.003125 169.18575 \nL 113.427125 169.18575 \nL 113.427125 109.38975 \nL 42.003125 109.38975 \nz\n\" style=\"fill:#09529d;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 113.427125 109.38975 \nL 113.427125 169.18575 \nL 184.851125 169.18575 \nL 184.851125 109.38975 \nL 113.427125 109.38975 \nz\n\" style=\"fill:#d9e8f5;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 184.851125 109.38975 \nL 184.851125 169.18575 \nL 256.275125 169.18575 \nL 256.275125 109.38975 \nL 184.851125 109.38975 \nz\n\" style=\"fill:#09529d;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 256.275125 109.38975 \nL 256.275125 169.18575 \nL 327.699125 169.18575 \nL 327.699125 109.38975 \nL 256.275125 109.38975 \nz\n\" style=\"fill:#084285;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 327.699125 109.38975 \nL 327.699125 169.18575 \nL 399.123125 169.18575 \nL 399.123125 109.38975 \nL 327.699125 109.38975 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 42.003125 169.18575 \nL 42.003125 228.98175 \nL 113.427125 228.98175 \nL 113.427125 169.18575 \nL 42.003125 169.18575 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 113.427125 169.18575 \nL 113.427125 228.98175 \nL 184.851125 228.98175 \nL 184.851125 169.18575 \nL 113.427125 169.18575 \nz\n\" style=\"fill:#084990;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 184.851125 169.18575 \nL 184.851125 228.98175 \nL 256.275125 228.98175 \nL 256.275125 169.18575 \nL 184.851125 169.18575 \nz\n\" style=\"fill:#7fb9da;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 256.275125 169.18575 \nL 256.275125 228.98175 \nL 327.699125 228.98175 \nL 327.699125 169.18575 \nL 256.275125 169.18575 \nz\n\" style=\"fill:#71b1d7;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 327.699125 169.18575 \nL 327.699125 228.98175 \nL 399.123125 228.98175 \nL 399.123125 169.18575 \nL 327.699125 169.18575 \nz\n\" style=\"fill:#083674;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 42.003125 228.98175 \nL 42.003125 288.77775 \nL 113.427125 288.77775 \nL 113.427125 228.98175 \nL 42.003125 228.98175 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 113.427125 228.98175 \nL 113.427125 288.77775 \nL 184.851125 288.77775 \nL 184.851125 228.98175 \nL 113.427125 228.98175 \nz\n\" style=\"fill:#08326e;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 184.851125 228.98175 \nL 184.851125 288.77775 \nL 256.275125 288.77775 \nL 256.275125 228.98175 \nL 184.851125 228.98175 \nz\n\" style=\"fill:#084c95;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 256.275125 228.98175 \nL 256.275125 288.77775 \nL 327.699125 288.77775 \nL 327.699125 228.98175 \nL 256.275125 228.98175 \nz\n\" style=\"fill:#f7fbff;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 327.699125 228.98175 \nL 327.699125 288.77775 \nL 399.123125 288.77775 \nL 399.123125 228.98175 \nL 327.699125 228.98175 \nz\n\" style=\"fill:#084285;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 42.003125 288.77775 \nL 42.003125 348.57375 \nL 113.427125 348.57375 \nL 113.427125 288.77775 \nL 42.003125 288.77775 \nz\n\" style=\"fill:#08326e;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 113.427125 288.77775 \nL 113.427125 348.57375 \nL 184.851125 348.57375 \nL 184.851125 288.77775 \nL 113.427125 288.77775 \nz\n\" style=\"fill:#08306b;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 184.851125 288.77775 \nL 184.851125 348.57375 \nL 256.275125 348.57375 \nL 256.275125 288.77775 \nL 184.851125 288.77775 \nz\n\" style=\"fill:#083471;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 256.275125 288.77775 \nL 256.275125 348.57375 \nL 327.699125 348.57375 \nL 327.699125 288.77775 \nL 256.275125 288.77775 \nz\n\" style=\"fill:#3686c0;\"/>\n    <path clip-path=\"url(#pdc3cdf346d)\" d=\"M 327.699125 288.77775 \nL 327.699125 348.57375 \nL 399.123125 348.57375 \nL 399.123125 288.77775 \nL 327.699125 288.77775 \nz\n\" style=\"fill:#d5e5f4;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 42.003125 348.57375 \nL 42.003125 49.59375 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 399.123125 348.57375 \nL 399.123125 49.59375 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 42.003125 348.57375 \nL 399.123125 348.57375 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 42.003125 49.59375 \nL 399.123125 49.59375 \n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pf955983b65)\" d=\"M 421.443125 348.57375 \nL 421.443125 347.405859 \nL 421.443125 50.761641 \nL 421.443125 49.59375 \nL 436.392125 49.59375 \nL 436.392125 50.761641 \nL 436.392125 347.405859 \nL 436.392125 348.57375 \nz\n\" style=\"fill:#eaeaf2;stroke:#eaeaf2;stroke-linejoin:miter;stroke-width:0.01;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\"/>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\"/>\n     <g id=\"text_11\">\n      <!-- 0.1 -->\n      <defs>\n       <path d=\"M 51.703125 34.421875 \nQ 51.703125 24.515625 49.828125 17.75 \nQ 47.953125 10.984375 44.703125 6.8125 \nQ 41.453125 2.640625 37.0625 0.828125 \nQ 32.671875 -0.984375 27.6875 -0.984375 \nQ 22.65625 -0.984375 18.3125 0.828125 \nQ 13.96875 2.640625 10.765625 6.78125 \nQ 7.5625 10.9375 5.734375 17.703125 \nQ 3.90625 24.46875 3.90625 34.421875 \nQ 3.90625 44.828125 5.734375 51.640625 \nQ 7.5625 58.453125 10.78125 62.5 \nQ 14.015625 66.546875 18.40625 68.1875 \nQ 22.796875 69.828125 27.984375 69.828125 \nQ 32.90625 69.828125 37.21875 68.1875 \nQ 41.546875 66.546875 44.765625 62.5 \nQ 48 58.453125 49.84375 51.640625 \nQ 51.703125 44.828125 51.703125 34.421875 \nz\nM 42.78125 34.421875 \nQ 42.78125 42.625 41.796875 48.0625 \nQ 40.828125 53.515625 38.921875 56.765625 \nQ 37.015625 60.015625 34.25 61.359375 \nQ 31.5 62.703125 27.984375 62.703125 \nQ 24.265625 62.703125 21.4375 61.328125 \nQ 18.609375 59.96875 16.671875 56.71875 \nQ 14.75 53.46875 13.765625 48.015625 \nQ 12.796875 42.578125 12.796875 34.421875 \nQ 12.796875 26.515625 13.796875 21.09375 \nQ 14.796875 15.671875 16.71875 12.375 \nQ 18.65625 9.078125 21.4375 7.640625 \nQ 24.21875 6.203125 27.78125 6.203125 \nQ 31.25 6.203125 34.03125 7.640625 \nQ 36.8125 9.078125 38.734375 12.375 \nQ 40.671875 15.671875 41.71875 21.09375 \nQ 42.78125 26.515625 42.78125 34.421875 \nz\n\" id=\"LiberationSans-48\"/>\n       <path d=\"M 7.625 0 \nL 7.625 7.46875 \nL 25.140625 7.46875 \nL 25.140625 60.40625 \nL 9.625 49.3125 \nL 9.625 57.625 \nL 25.875 68.796875 \nL 33.984375 68.796875 \nL 33.984375 7.46875 \nL 50.734375 7.46875 \nL 50.734375 0 \nz\n\" id=\"LiberationSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 318.112629)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\"/>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 5.03125 0 \nL 5.03125 6.203125 \nQ 7.515625 11.921875 11.109375 16.28125 \nQ 14.703125 20.65625 18.65625 24.1875 \nQ 22.609375 27.734375 26.484375 30.765625 \nQ 30.375 33.796875 33.5 36.8125 \nQ 36.625 39.84375 38.546875 43.15625 \nQ 40.484375 46.484375 40.484375 50.6875 \nQ 40.484375 53.609375 39.59375 55.828125 \nQ 38.71875 58.0625 37.0625 59.5625 \nQ 35.40625 61.078125 33.078125 61.828125 \nQ 30.765625 62.59375 27.9375 62.59375 \nQ 25.296875 62.59375 22.96875 61.859375 \nQ 20.65625 61.140625 18.84375 59.671875 \nQ 17.046875 58.203125 15.890625 56.03125 \nQ 14.75 53.859375 14.40625 50.984375 \nL 5.421875 51.8125 \nQ 5.859375 55.515625 7.46875 58.78125 \nQ 9.078125 62.0625 11.90625 64.53125 \nQ 14.75 67 18.71875 68.40625 \nQ 22.703125 69.828125 27.9375 69.828125 \nQ 33.0625 69.828125 37.0625 68.609375 \nQ 41.0625 67.390625 43.8125 64.984375 \nQ 46.578125 62.59375 48.046875 59.078125 \nQ 49.515625 55.5625 49.515625 50.984375 \nQ 49.515625 47.515625 48.265625 44.390625 \nQ 47.015625 41.265625 44.9375 38.421875 \nQ 42.875 35.59375 40.140625 32.953125 \nQ 37.40625 30.328125 34.421875 27.8125 \nQ 31.453125 25.296875 28.421875 22.828125 \nQ 25.390625 20.359375 22.71875 17.859375 \nQ 20.0625 15.375 17.96875 12.8125 \nQ 15.875 10.25 14.703125 7.46875 \nL 50.59375 7.46875 \nL 50.59375 0 \nz\n\" id=\"LiberationSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 281.442498)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_13\"/>\n     <g id=\"text_13\">\n      <!-- 0.3 -->\n      <defs>\n       <path d=\"M 51.21875 19 \nQ 51.21875 14.265625 49.671875 10.546875 \nQ 48.140625 6.84375 45.1875 4.265625 \nQ 42.234375 1.703125 37.859375 0.359375 \nQ 33.5 -0.984375 27.875 -0.984375 \nQ 21.484375 -0.984375 17.109375 0.609375 \nQ 12.75 2.203125 9.90625 4.8125 \nQ 7.078125 7.421875 5.65625 10.765625 \nQ 4.25 14.109375 3.8125 17.671875 \nL 12.890625 18.5 \nQ 13.28125 15.765625 14.328125 13.515625 \nQ 15.375 11.28125 17.1875 9.671875 \nQ 19 8.0625 21.625 7.171875 \nQ 24.265625 6.296875 27.875 6.296875 \nQ 34.515625 6.296875 38.296875 9.5625 \nQ 42.09375 12.84375 42.09375 19.28125 \nQ 42.09375 23.09375 40.40625 25.40625 \nQ 38.71875 27.734375 36.203125 29.03125 \nQ 33.6875 30.328125 30.734375 30.765625 \nQ 27.78125 31.203125 25.296875 31.203125 \nL 20.3125 31.203125 \nL 20.3125 38.8125 \nL 25.09375 38.8125 \nQ 27.59375 38.8125 30.265625 39.328125 \nQ 32.953125 39.84375 35.171875 41.1875 \nQ 37.40625 42.53125 38.84375 44.828125 \nQ 40.28125 47.125 40.28125 50.6875 \nQ 40.28125 56.203125 37.03125 59.390625 \nQ 33.796875 62.59375 27.390625 62.59375 \nQ 21.578125 62.59375 17.984375 59.609375 \nQ 14.40625 56.640625 13.8125 51.21875 \nL 4.984375 51.90625 \nQ 5.515625 56.453125 7.46875 59.8125 \nQ 9.421875 63.1875 12.421875 65.40625 \nQ 15.4375 67.625 19.28125 68.71875 \nQ 23.140625 69.828125 27.484375 69.828125 \nQ 33.25 69.828125 37.390625 68.375 \nQ 41.546875 66.9375 44.1875 64.46875 \nQ 46.828125 62.015625 48.0625 58.6875 \nQ 49.3125 55.375 49.3125 51.609375 \nQ 49.3125 48.578125 48.484375 45.9375 \nQ 47.65625 43.3125 45.890625 41.203125 \nQ 44.140625 39.109375 41.421875 37.59375 \nQ 38.71875 36.078125 34.90625 35.296875 \nL 34.90625 35.109375 \nQ 39.0625 34.671875 42.140625 33.21875 \nQ 45.21875 31.78125 47.21875 29.625 \nQ 49.21875 27.484375 50.21875 24.75 \nQ 51.21875 22.015625 51.21875 19 \nz\n\" id=\"LiberationSans-51\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 244.772367)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_14\"/>\n     <g id=\"text_14\">\n      <!-- 0.4 -->\n      <defs>\n       <path d=\"M 43.015625 15.578125 \nL 43.015625 0 \nL 34.71875 0 \nL 34.71875 15.578125 \nL 2.296875 15.578125 \nL 2.296875 22.40625 \nL 33.796875 68.796875 \nL 43.015625 68.796875 \nL 43.015625 22.515625 \nL 52.6875 22.515625 \nL 52.6875 15.578125 \nz\nM 34.71875 58.890625 \nQ 34.625 58.640625 34.234375 57.9375 \nQ 33.84375 57.234375 33.34375 56.34375 \nQ 32.859375 55.46875 32.34375 54.5625 \nQ 31.84375 53.65625 31.453125 53.078125 \nL 13.8125 27.09375 \nQ 13.578125 26.703125 13.109375 26.0625 \nQ 12.640625 25.4375 12.15625 24.78125 \nQ 11.671875 24.125 11.171875 23.484375 \nQ 10.6875 22.859375 10.40625 22.515625 \nL 34.71875 22.515625 \nz\n\" id=\"LiberationSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 208.102237)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_15\"/>\n     <g id=\"text_15\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 51.421875 22.40625 \nQ 51.421875 17.234375 49.859375 12.9375 \nQ 48.296875 8.640625 45.21875 5.53125 \nQ 42.140625 2.4375 37.578125 0.71875 \nQ 33.015625 -0.984375 27 -0.984375 \nQ 21.578125 -0.984375 17.546875 0.28125 \nQ 13.53125 1.5625 10.734375 3.78125 \nQ 7.953125 6 6.3125 8.984375 \nQ 4.6875 11.96875 4 15.375 \nL 12.890625 16.40625 \nQ 13.421875 14.453125 14.390625 12.625 \nQ 15.375 10.796875 17.0625 9.34375 \nQ 18.75 7.90625 21.21875 7.046875 \nQ 23.6875 6.203125 27.203125 6.203125 \nQ 30.609375 6.203125 33.390625 7.25 \nQ 36.1875 8.296875 38.15625 10.34375 \nQ 40.140625 12.40625 41.203125 15.375 \nQ 42.28125 18.359375 42.28125 22.21875 \nQ 42.28125 25.390625 41.25 28.046875 \nQ 40.234375 30.71875 38.328125 32.640625 \nQ 36.421875 34.578125 33.65625 35.640625 \nQ 30.90625 36.71875 27.390625 36.71875 \nQ 25.203125 36.71875 23.34375 36.328125 \nQ 21.484375 35.9375 19.890625 35.25 \nQ 18.3125 34.578125 17.015625 33.671875 \nQ 15.71875 32.765625 14.59375 31.78125 \nL 6 31.78125 \nL 8.296875 68.796875 \nL 47.40625 68.796875 \nL 47.40625 61.328125 \nL 16.3125 61.328125 \nL 14.984375 39.5 \nQ 17.328125 41.3125 20.84375 42.59375 \nQ 24.359375 43.890625 29.203125 43.890625 \nQ 34.328125 43.890625 38.421875 42.328125 \nQ 42.53125 40.765625 45.40625 37.90625 \nQ 48.296875 35.0625 49.859375 31.109375 \nQ 51.421875 27.15625 51.421875 22.40625 \nz\n\" id=\"LiberationSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 171.432106)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_16\"/>\n     <g id=\"text_16\">\n      <!-- 0.6 -->\n      <defs>\n       <path d=\"M 51.21875 22.515625 \nQ 51.21875 17.328125 49.78125 13 \nQ 48.34375 8.6875 45.53125 5.578125 \nQ 42.71875 2.484375 38.5625 0.75 \nQ 34.421875 -0.984375 29 -0.984375 \nQ 23 -0.984375 18.5 1.3125 \nQ 14.015625 3.609375 11.03125 7.921875 \nQ 8.0625 12.25 6.5625 18.53125 \nQ 5.078125 24.8125 5.078125 32.8125 \nQ 5.078125 42 6.765625 48.921875 \nQ 8.453125 55.859375 11.625 60.5 \nQ 14.796875 65.140625 19.359375 67.484375 \nQ 23.921875 69.828125 29.6875 69.828125 \nQ 33.203125 69.828125 36.28125 69.09375 \nQ 39.359375 68.359375 41.875 66.71875 \nQ 44.390625 65.09375 46.28125 62.40625 \nQ 48.1875 59.71875 49.3125 55.8125 \nL 40.921875 54.296875 \nQ 39.546875 58.734375 36.546875 60.71875 \nQ 33.546875 62.703125 29.59375 62.703125 \nQ 25.984375 62.703125 23.046875 60.984375 \nQ 20.125 59.28125 18.0625 55.875 \nQ 16.015625 52.484375 14.90625 47.359375 \nQ 13.8125 42.234375 13.8125 35.40625 \nQ 16.21875 39.84375 20.5625 42.15625 \nQ 24.90625 44.484375 30.515625 44.484375 \nQ 35.203125 44.484375 39.015625 42.96875 \nQ 42.828125 41.453125 45.53125 38.59375 \nQ 48.25 35.75 49.734375 31.671875 \nQ 51.21875 27.59375 51.21875 22.515625 \nz\nM 42.28125 22.125 \nQ 42.28125 25.6875 41.40625 28.5625 \nQ 40.53125 31.453125 38.765625 33.46875 \nQ 37.015625 35.5 34.421875 36.59375 \nQ 31.84375 37.703125 28.421875 37.703125 \nQ 26.03125 37.703125 23.578125 36.984375 \nQ 21.140625 36.28125 19.15625 34.6875 \nQ 17.1875 33.109375 15.9375 30.515625 \nQ 14.703125 27.9375 14.703125 24.21875 \nQ 14.703125 20.40625 15.671875 17.109375 \nQ 16.65625 13.8125 18.484375 11.375 \nQ 20.3125 8.9375 22.890625 7.515625 \nQ 25.484375 6.109375 28.71875 6.109375 \nQ 31.890625 6.109375 34.40625 7.203125 \nQ 36.921875 8.296875 38.671875 10.375 \nQ 40.4375 12.453125 41.359375 15.421875 \nQ 42.28125 18.40625 42.28125 22.125 \nz\n\" id=\"LiberationSans-54\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 134.761975)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_12\">\n     <g id=\"line2d_17\"/>\n     <g id=\"text_17\">\n      <!-- 0.7 -->\n      <defs>\n       <path d=\"M 50.59375 61.671875 \nQ 45.40625 53.765625 41.0625 46.453125 \nQ 36.71875 39.15625 33.59375 31.75 \nQ 30.46875 24.359375 28.734375 16.578125 \nQ 27 8.796875 27 0 \nL 17.828125 0 \nQ 17.828125 8.25 19.78125 16.1875 \nQ 21.734375 24.125 25.046875 31.765625 \nQ 28.375 39.40625 32.765625 46.78125 \nQ 37.15625 54.15625 42.09375 61.328125 \nL 5.125 61.328125 \nL 5.125 68.796875 \nL 50.59375 68.796875 \nz\n\" id=\"LiberationSans-55\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 98.091844)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_13\">\n     <g id=\"line2d_18\"/>\n     <g id=\"text_18\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 51.265625 19.1875 \nQ 51.265625 14.796875 49.875 11.109375 \nQ 48.484375 7.421875 45.625 4.734375 \nQ 42.78125 2.046875 38.328125 0.53125 \nQ 33.890625 -0.984375 27.828125 -0.984375 \nQ 21.78125 -0.984375 17.359375 0.53125 \nQ 12.9375 2.046875 10.03125 4.703125 \nQ 7.125 7.375 5.734375 11.0625 \nQ 4.34375 14.75 4.34375 19.09375 \nQ 4.34375 22.859375 5.484375 25.78125 \nQ 6.640625 28.71875 8.5625 30.828125 \nQ 10.5 32.953125 12.96875 34.25 \nQ 15.4375 35.546875 18.0625 35.984375 \nL 18.0625 36.1875 \nQ 15.1875 36.859375 12.90625 38.375 \nQ 10.640625 39.890625 9.09375 42.015625 \nQ 7.5625 44.140625 6.75 46.71875 \nQ 5.953125 49.3125 5.953125 52.203125 \nQ 5.953125 55.8125 7.34375 59 \nQ 8.734375 62.203125 11.46875 64.625 \nQ 14.203125 67.046875 18.25 68.4375 \nQ 22.3125 69.828125 27.640625 69.828125 \nQ 33.25 69.828125 37.375 68.40625 \nQ 41.5 67 44.203125 64.578125 \nQ 46.921875 62.15625 48.234375 58.9375 \nQ 49.5625 55.71875 49.5625 52.09375 \nQ 49.5625 49.265625 48.75 46.671875 \nQ 47.953125 44.09375 46.40625 41.96875 \nQ 44.875 39.84375 42.59375 38.34375 \nQ 40.328125 36.859375 37.359375 36.28125 \nL 37.359375 36.078125 \nQ 40.328125 35.59375 42.859375 34.296875 \nQ 45.40625 33.015625 47.265625 30.890625 \nQ 49.125 28.765625 50.1875 25.828125 \nQ 51.265625 22.90625 51.265625 19.1875 \nz\nM 40.4375 51.609375 \nQ 40.4375 54.203125 39.765625 56.34375 \nQ 39.109375 58.5 37.59375 60.03125 \nQ 36.078125 61.578125 33.640625 62.421875 \nQ 31.203125 63.28125 27.640625 63.28125 \nQ 24.171875 63.28125 21.78125 62.421875 \nQ 19.390625 61.578125 17.84375 60.03125 \nQ 16.3125 58.5 15.625 56.34375 \nQ 14.9375 54.203125 14.9375 51.609375 \nQ 14.9375 49.5625 15.46875 47.40625 \nQ 16.015625 45.265625 17.421875 43.5 \nQ 18.84375 41.75 21.328125 40.625 \nQ 23.828125 39.5 27.734375 39.5 \nQ 31.890625 39.5 34.40625 40.625 \nQ 36.921875 41.75 38.25 43.5 \nQ 39.59375 45.265625 40.015625 47.40625 \nQ 40.4375 49.5625 40.4375 51.609375 \nz\nM 42.140625 20.015625 \nQ 42.140625 22.515625 41.453125 24.828125 \nQ 40.765625 27.15625 39.109375 28.9375 \nQ 37.453125 30.71875 34.640625 31.8125 \nQ 31.84375 32.90625 27.640625 32.90625 \nQ 23.78125 32.90625 21.0625 31.8125 \nQ 18.359375 30.71875 16.671875 28.90625 \nQ 14.984375 27.09375 14.203125 24.71875 \nQ 13.421875 22.359375 13.421875 19.828125 \nQ 13.421875 16.65625 14.203125 14.03125 \nQ 14.984375 11.421875 16.6875 9.546875 \nQ 18.40625 7.671875 21.1875 6.640625 \nQ 23.96875 5.609375 27.9375 5.609375 \nQ 31.9375 5.609375 34.671875 6.640625 \nQ 37.40625 7.671875 39.0625 9.546875 \nQ 40.71875 11.421875 41.421875 14.078125 \nQ 42.140625 16.75 42.140625 20.015625 \nz\n\" id=\"LiberationSans-56\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(443.392125 61.421714)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-46\"/>\n       <use x=\"83.398438\" xlink:href=\"#LiberationSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <image height=\"299\" id=\"imagedc1aaab553\" transform=\"scale(1 -1)translate(0 -299)\" width=\"15\" x=\"421\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAAA8AAAErCAYAAAABnNneAAAABHNCSVQICAgIfAhkiAAAAWFJREFUeJztm8GNw0AMA3cNP66c9JX+37ka7AE8GFj+E8ySoqQ1nP33+f7Wzedc+7iLXefam4Al5vu0652CjVUPMxPwIf1salWxPKPMY9XD4GmAzzFvC0ytAmDtzCKYCMasigqmqS2m6oWCVRvgqH0RPA3wSfA7G+AwX3mYVQe5uTcF684qBI6qLTGPVRnmrlVFtcVZ5Ql2NK0Csz1r1QY7MxKsmqpobWt5hsFAYKsZRGcVDQYAM8HuE1fzLC5xTcFOolg1VV4kITMAe7MKVhhhFjcDBI42QMKs7dtaM1DXCsTcbICgwqqpMhtg8xZLwNVlnTBHX+NFfdbObL7GY8wATCaG9/bRnFWeYMndk74DLJaneE0QZxUBe8OdfTf0Qquagnln7jZAAG4WyaTqOjMAT6ougptFMqm6zgzAk6onmdcLU+Xdq2CeCbiZqqZg0Vllfl2bbL3mP3KTgnln9mr7H6/jCEJx9UtRAAAAAElFTkSuQmCC\" y=\"-49\"/>\n   <g id=\"patch_8\">\n    <path d=\"M 421.443125 348.57375 \nL 421.443125 347.405859 \nL 421.443125 50.761641 \nL 421.443125 49.59375 \nL 436.392125 49.59375 \nL 436.392125 50.761641 \nL 436.392125 347.405859 \nL 436.392125 348.57375 \nz\n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdc3cdf346d\">\n   <rect height=\"298.98\" width=\"357.12\" x=\"42.003125\" y=\"49.59375\"/>\n  </clipPath>\n  <clipPath id=\"pf955983b65\">\n   <rect height=\"298.98\" width=\"14.949\" x=\"421.443125\" y=\"49.59375\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{}}],"source":["plot_attention(translator, 'ich bin ein kartoffel .')"]},{"cell_type":"code","source":[],"metadata":{"id":"kSbTVmtCY_8A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9JJ8HOwzCutT"},"source":["Use these heatmaps to inspect the attention patterns for selected German sentences. Try to find sentences for which the model produces reasonably good English translations. If your German is a bit rusty (or non-existent), use sentences from the validation data. It might be interesting to look at examples where the German and the English word order differ substantially. Document your exploration in a short reflection piece (ca. 150¬†words). Respond to the following prompts:\n","\n","* What sentences did you try out? What patterns did you spot? Include example heatmaps in your notebook.\n","\"es war einmal ein junge\" \"there once was a boy\" : Translated to \"It was once a boy\". Maybe \"it\" should have been \"there\" but otherwise, the main idea of there once being a boy was captured by the model. This can also be noted by watching the model attending to the word \"einmal\" or \"once.\n","\n","* Based on what you know about attention, did you expect your results? Was there anything surprising in them?\n","We believe we got the expected results. I.e., the sentence \"ich habe ein traum .\" the word \"dream\" was central. This is because that particullar word is in fact central for the sentence. Without the word dream the sentence becomes arbitrary and can instead be the sentence \"ich bin ein fu√üball\". We also see that the common words \"ich\" are not given much attention.\n","\n","* What did you learn? How, exactly, did you learn it? Why does this learning matter?\n","We learned how to build models that take all the previous outputs into account, not only the last part (unrolling). This is bone by stepping through the model. We now know how to fix wrong tensor-sizes, and to match different tensors before performing calculations on them. "]},{"cell_type":"markdown","metadata":{"id":"jJ3wGRnPAW1H"},"source":["**ü•≥ Congratulations on finishing this lab! ü•≥**"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"vscode":{"interpreter":{"hash":"bc143343ca8435bba8c44b3b1f47f9edcb7f00f13cf7dc8cb9f5e5ffbd446b7a"}}},"nbformat":4,"nbformat_minor":0}